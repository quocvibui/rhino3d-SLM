{
  "source_url": "https://github.com/huhuman/rhino-defect-synth/blob/aec9f34c7273f7dcfcfdce7893e8ad91d8771c06/utils_loc/camera.py",
  "repo": "huhuman/rhino-defect-synth",
  "repo_stars": 0,
  "repo_description": "Rhino Python scripts for parametric synthetic defect image generation",
  "license": "unknown",
  "filepath": "utils_loc/camera.py",
  "instruction": "Camera positioning helpers.",
  "code": "\"\"\"Camera positioning helpers.\"\"\"\n\nimport math\nimport random\nfrom typing import Iterable, List, Mapping, Sequence, Tuple\n\nimport rhinoscriptsyntax as rs\nimport scriptcontext as sc\n\nVec3 = Tuple[float, float, float]\n\n\ndef _resolve_view_name(view_name=None):\n    \"\"\"Return a view name usable by rhinoscriptsyntax calls.\"\"\"\n    if view_name:\n        rhino_view = sc.doc.Views.Find(view_name, False)\n        if rhino_view is None:\n            raise ValueError(f\"View not found: {view_name}\")\n        return rhino_view.ActiveViewport.Name\n\n    rhino_view = sc.doc.Views.ActiveView\n    if rhino_view is None:\n        raise ValueError(\"No active view is available.\")\n    return rhino_view.ActiveViewport.Name\n\n\ndef _normalize(vec: Sequence[float]) -> Vec3:\n    \"\"\"Normalize a 3D vector; fall back to (0,0,1) if length is zero.\"\"\"\n    x, y, z = (float(v) for v in vec)\n    length = math.sqrt(x * x + y * y + z * z)\n    if length == 0:\n        return 0.0, 0.0, 1.0\n    inv = 1.0 / length\n    return x * inv, y * inv, z * inv\n\n\ndef _lerp(a: Sequence[float], b: Sequence[float], t: float) -> Vec3:\n    \"\"\"Linear interpolation between two 3D vectors.\"\"\"\n    return tuple(float(a[i]) + (float(b[i]) - float(a[i])) * t for i in range(3))\n\n\ndef _centroid(points: Sequence[Sequence[float]]) -> Vec3:\n    \"\"\"Compute centroid of a collection of 3D points.\"\"\"\n    if not points:\n        return 0.0, 0.0, 0.0\n    sx = sy = sz = 0.0\n    count = 0\n    for pt in points:\n        px, py, pz = (float(v) for v in pt)\n        sx += px\n        sy += py\n        sz += pz\n        count += 1\n    inv = 1.0 / float(count)\n    return sx * inv, sy * inv, sz * inv\n\n\ndef _linspace(start: float, stop: float, n: int) -> List[float]:\n    \"\"\"Simple linspace without numpy.\"\"\"\n    if n <= 1:\n        return [start]\n    step = (stop - start) / float(n - 1)\n    return [start + i * step for i in range(n)]\n\n\ndef set_camera(view_name=None, position=None, target=None, up=None, lens=None):\n    \"\"\"\n    Position a camera in the active or named view.\n\n    Args:\n        view_name: optional Rhino view name.\n        position: iterable of 3 floats.\n        target: iterable of 3 floats.\n        up: optional up vector.\n        lens: optional lens length / FOV override.\n    \"\"\"\n    if position is None or target is None:\n        raise ValueError(\"Both position and target are required to set the camera.\")\n\n    resolved_view = _resolve_view_name(view_name)\n    rs.ViewCameraTarget(resolved_view, position, target)\n    if up is not None:\n        rs.ViewCameraUp(resolved_view, up)\n    if lens is not None:\n        rs.ViewCameraLens(resolved_view, lens)\n    sc.doc.Views.Redraw()\n    return position, target\n\n\ndef set_camera_target(position, target, up=None):\n    \"\"\"Convenience wrapper for setting camera and target together.\"\"\"\n    return set_camera(position=position, target=target, up=up)\n\n\ndef move_camera(position: Iterable[float], direction: Iterable[float], view_name=None, distance=10.0, up=None, lens=None):\n    \"\"\"\n    Move the camera to a position and orient it along a direction vector.\n\n    Args:\n        position: camera location (x, y, z).\n        direction: direction vector to look toward.\n        view_name: optional Rhino view name.\n        distance: distance along the direction vector to place the target.\n        up: optional up vector override.\n        lens: optional lens length / FOV override.\n    \"\"\"\n    pos = tuple(float(p) for p in position)\n    dir_vec = _normalize(direction)\n    tgt = tuple(pos[i] + dir_vec[i] * float(distance) for i in range(3))\n    return set_camera(view_name=view_name, position=pos, target=tgt, up=up, lens=lens)\n\n\ndef generate_box_camera_grid(center: Iterable[float], lengths: Iterable[float], n: int) -> List[Mapping[str, Vec3]]:\n    \"\"\"\n    Generate camera positions around a box (6 faces, n x n points per face).\n\n    Args:\n        center: box center (x, y, z).\n        lengths: box side lengths (lx, ly, lz).\n        n: number of camera points per edge (>=2).\n\n    Returns:\n        List of dicts with position, target (center), and direction (toward center).\n    \"\"\"\n    if n < 2:\n        raise ValueError(\"n must be >= 2 to form a grid.\")\n\n    cx, cy, cz = (float(v) for v in center)\n    lx, ly, lz = (float(v) for v in lengths)\n    hx, hy, hz = lx * 0.5, ly * 0.5, lz * 0.5\n\n    xs = _linspace(cx - hx, cx + hx, n)\n    ys = _linspace(cy - hy, cy + hy, n)\n    zs = _linspace(cz - hz, cz + hz, n)\n\n    faces = [\n        ([(cx + hx, y, z) for y in ys for z in zs]),  # +X\n        ([(cx - hx, y, z) for y in ys for z in zs]),  # -X\n        ([(x, cy + hy, z) for x in xs for z in zs]),  # +Y\n        ([(x, cy - hy, z) for x in xs for z in zs]),  # -Y\n        ([(x, y, cz + hz) for x in xs for y in ys]),  # +Z\n        ([(x, y, cz - hz) for x in xs for y in ys]),  # -Z\n    ]\n\n    poses = []\n    seen = set()\n    center_pt: Vec3 = (cx, cy, cz)\n\n    for pts in faces:\n        for pt in pts:\n            key = tuple(round(c, 6) for c in pt)\n            if key in seen:\n                continue\n            seen.add(key)\n            dir_vec = _normalize(center_pt[i] - pt[i] for i in range(3))\n            poses.append(\n                {\n                    \"position\": pt,\n                    \"target\": center_pt,\n                    \"direction\": dir_vec,\n                }\n            )\n    return poses\n\n\ndef jitter_camera_poses(poses: List[Mapping[str, Vec3]], position_jitter=0.0, direction_jitter_degrees=0.0) -> List[Mapping[str, Vec3]]:\n    \"\"\"\n    Apply small random offsets to camera positions and directions.\n\n    Args:\n        poses: list from `generate_box_camera_grid`.\n        position_jitter: max absolute positional offset per axis (model units).\n        direction_jitter_degrees: max angular jitter for the look direction.\n    \"\"\"\n    pos_j = float(position_jitter)\n    dir_j = float(direction_jitter_degrees)\n\n    def jitter_dir(dir_vec: Vec3) -> Vec3:\n        if dir_j <= 0:\n            return dir_vec\n        # Perturb direction by adding a small random vector and renormalizing.\n        max_delta = math.tan(math.radians(dir_j))\n        delta = (\n            random.uniform(-max_delta, max_delta),\n            random.uniform(-max_delta, max_delta),\n            random.uniform(-max_delta, max_delta),\n        )\n        perturbed = tuple(dir_vec[i] + delta[i] for i in range(3))\n        return _normalize(perturbed)\n\n    jittered = []\n    for pose in poses:\n        pos = pose[\"position\"]\n        dir_vec = pose[\"direction\"]\n        jittered_pos = tuple(\n            float(pos[i]) + (random.uniform(-pos_j, pos_j) if pos_j > 0 else 0.0)\n            for i in range(3)\n        )\n        jittered_dir = jitter_dir(dir_vec)\n        jittered.append(\n            {\n                \"position\": jittered_pos,\n                \"target\": pose.get(\"target\"),\n                \"direction\": jittered_dir,\n            }\n        )\n    return jittered\n\n\ndef sort_poses_topdown_circular(poses: List[Mapping[str, Vec3]], center: Vec3 = None, z_bin_tol: float = 1e-3) -> List[Mapping[str, Vec3]]:\n    \"\"\"Order poses from highest Z to lowest, and circularly within each layer.\n\n    Args:\n        poses: list of pose dicts (expects a \"position\" entry).\n        center: optional reference point for angle sorting; defaults to centroid of positions.\n        z_bin_tol: tolerance for grouping poses into the same Z layer.\n    \"\"\"\n    if not poses:\n        return poses\n\n    positions = [p[\"position\"] for p in poses]\n    cx, cy, cz = center if center is not None else _centroid(positions)\n    z_tol = max(1e-9, float(z_bin_tol))\n\n    # Group poses by Z layers using a tolerance bin.\n    layers = {}\n    for pose in poses:\n        z = float(pose[\"position\"][2])\n        key = round(z / z_tol)\n        if key not in layers:\n            layers[key] = {\"z\": z, \"items\": []}\n        layers[key][\"items\"].append(pose)\n\n    # Sort layer keys from top (largest Z) to bottom.\n    sorted_layers = sorted(layers.values(), key=lambda entry: entry[\"z\"], reverse=True)\n\n    ordered: List[Mapping[str, Vec3]] = []\n    for layer in sorted_layers:\n        items = layer[\"items\"]\n        # Sort clockwise around center (atan2 gives -pi..pi). Adjust to start at +X and go CCW.\n        def angle(p):\n            x, y, _ = (float(v) for v in p[\"position\"])\n            return math.atan2(y - cy, x - cx)\n\n        ordered.extend(sorted(items, key=angle))\n\n    return ordered\n\n\ndef _prepare_pose_for_animation(pose: Mapping[str, Vec3], fallback_distance: float) -> Mapping[str, Vec3]:\n    \"\"\"Ensure every pose has an explicit target for animation.\"\"\"\n    pos = tuple(float(v) for v in pose[\"position\"])\n    target = pose.get(\"target\")\n    direction = pose.get(\"direction\")\n\n    if target is None:\n        if direction is None:\n            raise ValueError(\"Each pose must define a target or direction.\")\n        dir_vec = _normalize(direction)\n        target = tuple(pos[i] + dir_vec[i] * fallback_distance for i in range(3))\n    else:\n        target = tuple(float(v) for v in target)\n\n    return {\"position\": pos, \"target\": target, \"direction\": direction}\n\n\ndef _interpolate_camera_path(resolved_poses: List[Mapping[str, Vec3]], frames_between: int) -> List[Mapping[str, Vec3]]:\n    \"\"\"Insert evenly spaced poses between each provided pose.\"\"\"\n    if frames_between <= 0 or len(resolved_poses) < 2:\n        return resolved_poses\n\n    frames: List[Mapping[str, Vec3]] = [resolved_poses[0]]\n    steps = int(frames_between)\n\n    for idx in range(len(resolved_poses) - 1):\n        start = resolved_poses[idx]\n        end = resolved_poses[idx + 1]\n\n        for step in range(1, steps + 1):\n            t = step / float(steps + 1)\n            interp_pos = _lerp(start[\"position\"], end[\"position\"], t)\n            # Keep the target fixed during interpolation to avoid zooming toward the midpoint.\n            interp_tgt = start[\"target\"]\n            frames.append({\"position\": interp_pos, \"target\": interp_tgt, \"direction\": end.get(\"direction\")})\n\n        frames.append(end)\n\n    return frames\n\n\ndef animate_camera_path(poses: List[Mapping[str, Vec3]], view_name=None, distance=None, dwell_ms=300, up=None, lens=None, transition_frames=0):\n    \"\"\"\n    Move the Rhino camera through a list of poses to visualize motion.\n\n    Args:\n        poses: list containing position/target/direction entries.\n        view_name: optional Rhino view name.\n        distance: optional override for direction-based target distance. Defaults to 10 units when None.\n        dwell_ms: pause in milliseconds between frames.\n        up: optional up vector override.\n        lens: optional lens length / FOV override.\n        transition_frames: number of linearly interpolated poses to insert between each input pose.\n    \"\"\"\n    if not poses:\n        return\n\n    resolved_view = _resolve_view_name(view_name)\n    sleep_ms = max(0, int(dwell_ms))\n    target_distance = 10.0 if distance is None else float(distance)\n\n    resolved_poses = [_prepare_pose_for_animation(p, target_distance) for p in poses]\n    frames = _interpolate_camera_path(resolved_poses, transition_frames)\n\n    for pose in frames:\n        pos = pose[\"position\"]\n        target = pose[\"target\"]\n\n        set_camera(view_name=resolved_view, position=pos, target=target, up=up, lens=lens)\n\n        if sleep_ms:\n            rs.Sleep(sleep_ms)\n\n\ndef animate_camera_path_jump(poses: List[Mapping[str, Vec3]], **kwargs):\n    \"\"\"Animate by jumping directly to each pose (backwards compatible helper).\"\"\"\n    return animate_camera_path(poses, transition_frames=0, **kwargs)\n\n\ndef animate_camera_path_transition(poses: List[Mapping[str, Vec3]], transition_frames=5, **kwargs):\n    \"\"\"Animate by linearly interpolating poses before moving the camera.\"\"\"\n    return animate_camera_path(poses, transition_frames=transition_frames, **kwargs)\n\n\ndef spin_camera_around_bbox(bbox, step_degrees=15, distance_scale=0.25):\n    \"\"\"\n    Generate camera poses around a bounding box for turntable renders.\n\n    Args:\n        bbox: bounding box tuple (max_x, min_x, max_y, min_y, max_z, min_z).\n        step_degrees: degrees to rotate per step.\n        distance_scale: relative distance multiplier from bbox extents.\n    \"\"\"\n    max_x, min_x, max_y, min_y, max_z, min_z = bbox\n    center = ((max_x + min_x) * 0.5, (max_y + min_y) * 0.5, (max_z + min_z) * 0.5)\n    radius = max(max_x - min_x, max_y - min_y) * distance_scale\n    z_height = center[2] + (max_z - min_z) * distance_scale\n\n    poses = []\n    angle = 0.0\n    while angle < 360.0:\n        rad = math.radians(angle)\n        pos = (\n            center[0] + radius * math.cos(rad),\n            center[1] + radius * math.sin(rad),\n            z_height,\n        )\n        dir_vec = _normalize(center[i] - pos[i] for i in range(3))\n        poses.append({\"position\": pos, \"target\": center, \"direction\": dir_vec})\n        angle += step_degrees\n    return poses\n",
  "language": "python",
  "imports": [
    "rhinoscriptsyntax",
    "scriptcontext"
  ],
  "has_docstring": true
}