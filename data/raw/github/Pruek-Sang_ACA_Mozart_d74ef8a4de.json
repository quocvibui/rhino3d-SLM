{
  "source_url": "https://github.com/Pruek-Sang/ACA_Mozart/blob/b995c75e5397de2ccbe20368fc3241a8f6f182f7/MCP-tool%2BAuto%20lisp%20GEN/RESEARCH/GPT_check.py",
  "repo": "Pruek-Sang/ACA_Mozart",
  "repo_stars": 0,
  "repo_description": "NLP to Design",
  "license": "unknown",
  "filepath": "MCP-tool+Auto lisp GEN/RESEARCH/GPT_check.py",
  "instruction": "Overall, this code seems to be much more smoothly written than the ChatGPT one, but it does not make use of the functions established there",
  "code": "# Overall, this code seems to be much more smoothly written than the ChatGPT one, but it does not make use of the functions established there\n\nif allow_run:\n    \n    import base64\n    import openai\n    from openai import OpenAI\n    from io import BytesIO\n    from PIL import Image\n    import os\n    import json\n    import rhinoscriptsyntax as rs\n\n    os.chdir(path)\n    change = False\n\n    taskfile = \"task.json\"\n\n    # get task\n    with open(taskfile, \"r\") as tf:\n        task = json.load(tf)\n\n    # load API-Key\n    key = open('key.txt', 'r')\n    api_key = key.read()\n\n    # define logfile\n    logfile = \"log.json\"\n\n    # hand over API-Key\n    #OPENAI_API_KEY = api_key\n\n    def encode_image(image_path, max_image=512):\n        with Image.open(image_path) as img:\n            width, height = img.size\n            max_dim = max(width, height)\n            if max_dim > max_image:\n                scale_factor = max_image / max_dim\n                new_width = int(width * scale_factor)\n                new_height = int(height * scale_factor)\n                img = img.resize((new_width, new_height))\n\n            buffered = BytesIO()\n            img.save(buffered, format=\"PNG\")\n            img_str = base64.b64encode(buffered.getvalue()).decode(\"utf-8\")\n            return img_str\n\n    key = open(\"key.txt\", \"r\")\n    api_key = key.read()\n    openai.api_key = api_key\n\n    #client = OpenAI()\n    image_file = image\n    max_size = 512  # set to maximum dimension to allow (512=1 tile, 2048=max)\n    encoded_string = encode_image(image_file, max_size)\n\n    system_prompt = task[\"step4\"]\n    user = (\"Here is the image of the part. Does it look like requested?\")\n\n    with open(logfile, \"r\") as tf:\n        messages_input = json.load(tf)\n\n    # function calling need to be deleted, because it can not be processed with this GPT-version\n    messages = [entry for entry in messages_input if \"function_call\" not in entry]\n\n    # replace system message\n    for item in messages:\n        if item[\"role\"] == \"system\":\n        # Update the content\n            item[\"content\"] = system_prompt\n\n    # insert user message and picture\n    messages.append(\n        {\n            \"role\": \"user\",\n            \"content\":\n            [\n                {\"type\": \"text\", \"text\": user},\n                {\n                    \"type\": \"image_url\",\n                    \"image_url\": {\"url\":\n                        f\"data:image/jpeg;base64,{encoded_string}\"}\n                }\n            ]\n        }\n    )\n\n    if go:\n        # apiresponse = client.chat.completions.with_raw_response.create(\n        #     model=\"gpt-4-vision-preview\",\n        #     messages=messages,\n        #     max_tokens=500,\n        # )\n\n        # currently set up only for ChatGPT\n        apiresponse = openai.chat.completions.with_raw_response.create(\n            model=\"gpt-4o\",\n            messages=messages,\n            max_tokens=500,\n        )\n        debug_sent = apiresponse.http_request.content\n        chat_completion = apiresponse.parse()\n        print(chat_completion.choices[0].message.content)\n        print(chat_completion.usage.model_dump())\n        print(\n            \"remaining-requests: \"\n            f\"{apiresponse.headers.get('x-ratelimit-remaining-requests')}\"\n        )\n\n        str_message = rs.EditBox(\n            default_string = \"Describe the contents and layout of my image.\",\n            message = chat_completion.choices[0].message.content,\n            title = \"GPT answer\"\n        )\n\n        response = chat_completion.choices[0].message.content\n\n        if \"CHANGE\" in response:\n            # add message\n            response = response.replace(\"CHANGE\",\"\")\n            messages_input.append({\"role\":\"user\",\"content\":\"Please check the result\"})\n            messages_input.append({\"role\":\"assistant\",\"content\":response})\n            # store in log file\n            with open(logfile, \"w\") as tf:\n                json.dump(messages_input, tf)\n            # improve\n            change = True",
  "language": "python",
  "imports": [
    "rhinoscriptsyntax"
  ],
  "has_docstring": true
}