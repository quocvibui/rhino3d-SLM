{
  "source_url": "https://github.com/leclusen/necs-sandbox/blob/8d8006ae3c845c9f3e38154803caac6b03d298a9/structure-batiment/analysis/object_diff_analysis.py",
  "repo": "leclusen/necs-sandbox",
  "repo_stars": 0,
  "repo_description": null,
  "license": "unknown",
  "filepath": "structure-batiment/analysis/object_diff_analysis.py",
  "instruction": "Analyze removed/added objects and line->polyline conversions between before/after 3dm.",
  "code": "#!/usr/bin/env python3\n\"\"\"Analyze removed/added objects and line->polyline conversions between before/after 3dm.\"\"\"\n\nfrom __future__ import annotations\n\nfrom collections import Counter, defaultdict\nfrom dataclasses import dataclass\nfrom pathlib import Path\nimport sqlite3\n\nimport numpy as np\nimport rhino3dm\n\nBEFORE = Path(\"data/input/before.3dm\")\nAFTER = Path(\"data/input/after.3dm\")\nDB = Path(\"data/input/geometrie_2.db\")\n\n\n@dataclass\nclass ObjInfo:\n    name: str\n    geom_type: str\n    bbox: tuple[float, float, float, float, float, float]\n    center: tuple[float, float, float]\n    layer: str\n\n\ndef load_model(path: Path):\n    model = rhino3dm.File3dm.Read(str(path))\n    if model is None:\n        raise RuntimeError(f\"Failed to read {path}\")\n    # Map layer id -> layer\n    layer_by_id = {str(l.Id): l for l in model.Layers}\n\n    def resolve_category(layer: rhino3dm.Layer):\n        current = layer\n        null_id = \"00000000-0000-0000-0000-000000000000\"\n        while str(current.ParentLayerId) != null_id and str(current.ParentLayerId) in layer_by_id:\n            current = layer_by_id[str(current.ParentLayerId)]\n        return current.Name\n\n    objs = {}\n    for obj in model.Objects:\n        nm = obj.Attributes.Name\n        if not nm:\n            continue\n        geom = obj.Geometry\n        gtype = type(geom).__name__\n        bbox = geom.GetBoundingBox()\n        bb_tuple = (bbox.Min.X, bbox.Min.Y, bbox.Min.Z, bbox.Max.X, bbox.Max.Y, bbox.Max.Z)\n        center = ((bbox.Min.X + bbox.Max.X) / 2, (bbox.Min.Y + bbox.Max.Y) / 2, (bbox.Min.Z + bbox.Max.Z) / 2)\n        layer = resolve_category(model.Layers[obj.Attributes.LayerIndex])\n        objs[nm] = ObjInfo(nm, gtype, bb_tuple, center, layer)\n    return objs\n\n\ndef load_shell_props(db_path: Path):\n    conn = sqlite3.connect(str(db_path))\n    cur = conn.cursor()\n    cur.execute(\"select name, type, thickness, cover_top, cover_bottom, material_id, modeling from shell\")\n    props = {row[0]: row[1:] for row in cur.fetchall()}\n    conn.close()\n    return props\n\n\ndef summarize_bbox(objs):\n    dx = []\n    dy = []\n    dz = []\n    zmin = []\n    zmax = []\n    centers_z = []\n    for o in objs:\n        xmin, ymin, z0, xmax, ymax, z1 = o.bbox\n        dx.append(xmax - xmin)\n        dy.append(ymax - ymin)\n        dz.append(z1 - z0)\n        zmin.append(z0)\n        zmax.append(z1)\n        centers_z.append(o.center[2])\n    def stats(arr):\n        return (float(np.min(arr)), float(np.max(arr)), float(np.median(arr)), float(np.mean(arr))) if arr else (0,0,0,0)\n    return {\n        'dx': stats(dx),\n        'dy': stats(dy),\n        'dz': stats(dz),\n        'zmin': stats(zmin),\n        'zmax': stats(zmax),\n        'cz': stats(centers_z),\n    }\n\n\ndef histogram_levels(values, round_mm=1.0, top=12):\n    vals_mm = np.round(np.array(values) * 1000 / round_mm) * round_mm\n    cnt = Counter(vals_mm)\n    return cnt.most_common(top)\n\n\ndef analyze():\n    before = load_model(BEFORE)\n    after = load_model(AFTER)\n    shell_props = load_shell_props(DB)\n\n    before_names = set(before)\n    after_names = set(after)\n\n    removed_names = sorted(before_names - after_names)\n    added_names = sorted(after_names - before_names)\n    common = before_names & after_names\n\n    removed = [before[n] for n in removed_names]\n    added = [after[n] for n in added_names]\n\n    print(f\"Removed objects: {len(removed)} (expected ~320)\")\n    print(f\"Added objects:   {len(added)} (expected ~476)\")\n\n    # Removed summary\n    print(\"\\n=== Removed ===\")\n    print(\"By layer:\", Counter(o.layer for o in removed).most_common())\n    print(\"By geom type:\", Counter(o.geom_type for o in removed).most_common())\n    stats = summarize_bbox(removed)\n    print(\"BBox stats (min, max, median, mean):\")\n    for k, v in stats.items():\n        print(f\"  {k}: {v}\")\n\n    zmins = [o.bbox[2] for o in removed]\n    print(\"Top Z-min levels (mm):\", histogram_levels(zmins))\n    zmids = [o.center[2] for o in removed]\n    print(\"Top center Z levels (mm):\", histogram_levels(zmids))\n\n    # Shell property join\n    matched = [o for o in removed if o.name.split('[')[0] in shell_props or o.name in shell_props]\n    matched_names = []\n    for o in removed:\n        key = o.name.split('[')[0]\n        if key in shell_props:\n            matched_names.append(key)\n    print(f\"Shell-table matches: {len(set(matched_names))}/{len(removed)}\")\n    shell_types = Counter()\n    thicknesses = []\n    modeling = Counter()\n    for n in set(matched_names):\n        t, thick, cover_t, cover_b, mat, mod = shell_props[n]\n        shell_types[t] += 1\n        thicknesses.append(thick)\n        modeling[mod] += 1\n    print(\"Shell types:\", shell_types.most_common())\n    if thicknesses:\n        print(f\"Thickness min/med/max: {min(thicknesses):.4f}/{np.median(thicknesses):.4f}/{max(thicknesses):.4f} m\")\n    print(\"Modeling modes:\", modeling.most_common())\n\n    # Added summary\n    print(\"\\n=== Added ===\")\n    print(\"By layer:\", Counter(o.layer for o in added).most_common())\n    print(\"By geom type:\", Counter(o.geom_type for o in added).most_common())\n    stats_a = summarize_bbox(added)\n    print(\"BBox stats (min, max, median, mean):\")\n    for k, v in stats_a.items():\n        print(f\"  {k}: {v}\")\n    zmins_a = [o.bbox[2] for o in added]\n    print(\"Top Z-min levels (mm):\", histogram_levels(zmins_a))\n    zmids_a = [o.center[2] for o in added]\n    print(\"Top center Z levels (mm):\", histogram_levels(zmids_a))\n\n    # Placement heuristic: XY positions rounded to 1mm\n    xy_round = lambda o: (round(o.center[0], 3), round(o.center[1], 3))\n    xy_counts = Counter(xy_round(o) for o in added)\n    duplicates = [item for item, c in xy_counts.items() if c > 1]\n    print(f\"Repeated XY centers (rounded 1mm): {len(duplicates)} occurrences with >1 objects\")\n\n    # Added supports vs columns: nearest XY distance to any Poteau center in AFTER\n    poteaux_after = [o for o in after.values() if o.layer == \"Poteau\"]\n    poteau_xy = np.array([[p.center[0], p.center[1]] for p in poteaux_after]) if poteaux_after else np.empty((0, 2))\n    appuis_added = [o for o in added if o.layer == \"Appuis\"]\n    if len(poteau_xy) > 0 and appuis_added:\n        dists = []\n        for a in appuis_added:\n            diff = poteau_xy - np.array([[a.center[0], a.center[1]]])\n            norm = np.sqrt(np.sum(diff**2, axis=1))\n            dists.append(float(np.min(norm)))\n        print(\"Nearest XY distance from added Appuis to any Poteau (m):\")\n        print(f\"  min/med/max/mean = {min(dists):.4f}/{np.median(dists):.4f}/{max(dists):.4f}/{np.mean(dists):.4f}\")\n        for thr in [0.05, 0.10, 0.20, 0.50]:\n            pct = sum(d <= thr for d in dists) / len(dists) * 100\n            print(f\"  within {thr:.2f} m: {pct:5.1f}% ({sum(d <= thr for d in dists)}/{len(dists)})\")\n\n    # Removed vs added shells: XY displacement between centers of nearest shell replacement\n    removed_shells = [o for o in removed if o.layer in (\"Dalle\", \"Voile\")]\n    added_shells = [o for o in added if o.layer in (\"Dalle\", \"Voile\")]\n    if removed_shells and added_shells:\n        added_xy = np.array([[s.center[0], s.center[1]] for s in added_shells])\n        disps = []\n        for r in removed_shells:\n            diff = added_xy - np.array([[r.center[0], r.center[1]]])\n            norm = np.sqrt(np.sum(diff**2, axis=1))\n            disps.append(float(np.min(norm)))\n        print(\"Nearest XY distance from removed shells to any added shell (m):\")\n        print(f\"  min/med/max/mean = {min(disps):.4f}/{np.median(disps):.4f}/{max(disps):.4f}/{np.mean(disps):.4f}\")\n        for thr in [0.05, 0.10, 0.25, 0.50]:\n            pct = sum(d <= thr for d in disps) / len(disps) * 100\n            print(f\"  within {thr:.2f} m: {pct:5.1f}% ({sum(d <= thr for d in disps)}/{len(disps)})\")\n\n    # Line->polyline conversions among common names\n    print(\"\\n=== LineCurve -> PolylineCurve conversions ===\")\n    conversions = []\n    for n in common:\n        gt_b = before[n].geom_type\n        gt_a = after[n].geom_type\n        if gt_b == \"LineCurve\" and gt_a == \"PolylineCurve\":\n            # count points in polyline\n            # reopen geometries for counts\n            conversions.append(n)\n    print(f\"Found {len(conversions)} conversions (expected 912)\")\n\n    if conversions:\n        # Need fresh access to geometry to count points\n        model_before = rhino3dm.File3dm.Read(str(BEFORE))\n        model_after = rhino3dm.File3dm.Read(str(AFTER))\n        obj_map_before = {obj.Attributes.Name: obj.Geometry for obj in model_before.Objects if obj.Attributes.Name}\n        obj_map_after = {obj.Attributes.Name: obj.Geometry for obj in model_after.Objects if obj.Attributes.Name}\n\n        more_than_two = 0\n        point_counts = []\n        for n in conversions:\n            poly = obj_map_after[n]\n            pc = poly.PointCount\n            point_counts.append(pc)\n            if pc > 2:\n                more_than_two += 1\n        pc_counter = Counter(point_counts)\n        print(\"Polyline point counts (after):\", pc_counter.most_common())\n        print(f\"With >2 points: {more_than_two}/{len(conversions)}\")\n\n\nif __name__ == \"__main__\":\n    analyze()\n",
  "language": "python",
  "imports": [
    "rhino3dm"
  ],
  "has_docstring": true
}