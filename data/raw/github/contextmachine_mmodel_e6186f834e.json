{
  "source_url": "https://github.com/contextmachine/mmodel/blob/0545e5c2a11c641fc54e91f603e709d3dea549f3/utils/utils.py",
  "repo": "contextmachine/mmodel",
  "repo_stars": 0,
  "repo_description": "Deployment branch",
  "license": "Apache-2.0",
  "filepath": "utils/utils.py",
  "instruction": "Copyright (c) 2022. Computational Geometry, Digital Engineering and Optimizing your construction processe\"",
  "code": "#  Copyright (c) 2022. Computational Geometry, Digital Engineering and Optimizing your construction processe\"\n\nfrom __future__ import annotations\n\nimport copy\nimport inspect\nimport math\nfrom itertools import *\n\nimport numpy as np\nimport rhino3dm\nfrom numpy import ndarray\nfrom rhino3dm import File3dm\nfrom shapely.geometry import Point, Polygon\n\n\ndef np_to_shapely_points(arr):\n    for a in arr:\n        yield Point(a[0], a[1])\n\n\ndef np_to_shapely_polygons(arr):\n    for a in arr:\n        poly = []\n        for pt in a:\n            poly.append([pt[0], pt[1]])\n        yield Polygon(poly)\n\n\n# imports/exports\n\ndef int_formatter(val: int):\n    if int(str(val), 10) in range(9):\n        return '0' + str(val)\n\n\ndef np_to_shapely_polygons_z(arr, z=None):\n    for a in arr:\n        poly = []\n        for pt in a:\n            if z is not None:\n                poly.append([pt[0], pt[1], z])\n            else:\n                poly.append([pt[0], pt[1], pt[2]])\n\n        yield Polygon(poly)\n\n\ndef extract_polygon_z(arr):\n    vals = []\n    for polygon in arr:\n        vals.append(np.unique(np.asarray(polygon)[..., 2])[0])\n    return vals\n\n\ndef create_set(iterable):\n    s = set()\n    for i in iterable:\n        s.add(i)\n    return s\n\n\ndef zip_transpose(zipped):\n    return zip(*zipped)\n\n\ndef filterf_(zipper):\n    # unz=list(zipper)\n    # # print(unz)\n    # dct = dict(unz)\n    # rint(dct.keys())\n    keys_ = []\n    vals_ = []\n    for k, v in zipper:\n        if k in keys_:\n            i = keys_.index(k)\n            vals_[i].append(v)\n        else:\n            keys_.append(k)\n            # # print(f'key append {k}')\n            vals_.append([v])\n    return [keys_, vals_]\n\n\ndef oo(n):\n    for i in inspect.getmembers(n):\n\n        # to remove private and protected\n        # functions\n        if not i[0].startswith('_'):\n            # To remove other methods that\n            # doesnot start with a underscore\n\n            # print(i)\n            yield i\n\n\nclass RhLinked(type):\n    def __new__(mcs, classname: str, file: str | File3dm, childnames=lambda x: getattr(x, \"Name\"), **attrs):\n        classes_ = {}\n        if type(file) == str:\n            fl = rhino3dm.File3dm.Read(file)\n\n        if type(file) == File3dm:\n            fl = file\n\n        classes_ |= {'file': fl}\n\n        def n_init(self, **kwargs):\n            for k, v in kwargs.items():\n                setattr(self, k, v)\n\n        objcts = fl.Objects\n        # objct = rhino3dm.File3dmObject\n        childset = set()\n        i_l = []\n        for objct in objcts:\n            # print(objct)\n            # attr_dict = objct.Attributes\n            i_dict = dict(objct.Geometry.GetUserStrings())\n\n            i_dict |= {'geometry': objct.Geometry}\n\n            i_dict |= {'geometry': objct.Geometry}\n            chn = childnames(objct)\n\n            attr_dict = {}\n            i_dict |= dict(oo(objct.Attributes))\n            for k in i_dict.keys():\n                attr_dict[k] = None\n\n            attr_dict |= {'instance_attrs': []}\n            # print(attr_dict)\n            childset.add(chn)\n            rh_mdl_cls = type(chn, (object,), attr_dict)\n\n            i_dict |= {'__init__': n_init}\n\n            i_l.append((chn, i_dict))\n            classes_ |= {chn: rh_mdl_cls}\n        for ch in childset:\n            classes_ |= {ch + '_objects': []}\n        # rh_cls = type(k, (object,), classes_)\n        # classes |= {k: rh_cls}\n        classes_ |= {'__childnames__': childset}\n        for nm, at in i_l:\n            # print(at)\n            if nm in childset:\n                # print(nm + '_objects')\n                # print(at)\n                cl = classes_[nm]\n                o = cl()\n                for k, v in at.items():\n                    setattr(o, k, v)\n                classes_[nm + '_objects'].append(o)\n\n        classes_ |= attrs\n\n        return type(classname, (object,), classes_)\n\n\ndef shortest_distance(x1, y1, z1, a, b, c, d):\n    d = abs((a * x1 + b * y1 + c * z1 + d))\n    e = (math.sqrt(a * a + b * b + c * c))\n    # print(\"Perpendicular distance is\", d / e)\n    return d / e\n\n\ndef remap_interval(OldValue, OldMin, OldMax, NewMin, NewMax):\n    OldRange = OldMax - OldMin\n    if OldRange == 0:\n        pass\n    # print(\"none domain length\")\n    else:\n\n        NewRange = NewMax - NewMin\n        NewValue = (OldValue - OldMin) * NewRange / OldRange + NewMin\n        return NewValue\n\n\ndef estimated(points, guids):\n    for i, gd in enumerate(guids):\n        for pt in points[i]:\n            yield np.asarray(pt) - np.asarray(gd)\n\n\ndef solve_wall_domain(points_):\n    listx = []\n    listy = []\n    listz = []\n    for i in points_:\n        listx.append(i[0])\n        listy.append(i[1])\n        listz.append(i[2])\n    listx.sort()\n    listy.sort()\n    listz.sort()\n    xmax, xmin = listx[0], listx[-1]\n    ymax, ymin = listx[1], listx[-1]\n    zmax, zmin = listz[1], listz[-1]\n    bounds = zip([xmax, xmin], [ymax, ymin], [zmax, zmin])\n    return bounds\n\n\ndef solve_normalize(points, bounds):\n    max_, min_ = bounds\n    xmx, ymx, zmx = max_\n    xmn, ymn, zmn = min_\n    for i in points:\n        x_ = remap_interval(i[0], xmn, xmx, 0.0, 1.0)\n        y_ = remap_interval(i[1], ymn, ymx, 0.0, 1.0)\n        z_ = remap_interval(i[2], zmn, zmx, 0.0, 1.0)\n        yield [x_, y_, z_]\n\n\n# compython geometry base methods\n\ndef get_clusters(data, labels):\n    \"\"\"\n    :param data: The dataset\n    :param labels: The label for each point in the dataset\n    :return: List[np.ndarray]: A list of arrays where the elements of each array\n    are data points belonging to the label at that ind\n    \"\"\"\n    return [data[np.where(labels == i)] for i in range(np.amax(labels) + 1)]\n\n\ndef map_domains(values, s_min, s_max, t_min, t_max):\n    # Remap numbers into new numeric domain\n    mapped = []\n    for v in values:\n        if s_max - s_min > 0:\n            rv = ((v - s_min) / (s_max - s_min)) * (t_max - t_min) + t_min\n        else:\n            rv = (t_min + t_max) / 2\n        mapped.append(rv)\n    return mapped\n\n\ndef mns(a, b, k=1.9):\n    l = list(zip(a, b))\n    sl = list(starmap(lambda x, y: abs(x) - abs(y), l))\n    ex = []\n    for s in sl:\n        u = abs(s) < k\n        ex.append(u)\n    # v = abs(sl[0]) < k and abs(sl[1]) < k and abs(sl[2]) < k\n    se = set(ex)\n    if se.__contains__(False):\n        return False\n    else:\n        return True\n\n\ndef match_planes(pts, k):\n    p = [pts[0]]\n    indxs = [p.index(pts[0])]\n\n    ptsq = pts[1:]\n\n    while True:\n\n        if len(ptsq) == 0:\n            break\n        pp = ptsq[0]\n\n        p.reverse()\n        for i in p:\n\n            # print(\"\\033[0, 37m{} {}\\033\".format(pp, i))\n\n            if mns(i, pts[0], k):\n                p.append(pp)\n\n            if mns(pp, i, k):\n                pii = p.index(i)\n                indxs.append(pii)\n                print(\"\\033[1;35;40mMatch(\\033[0;37;40m{}&{}\\033[1;35;40m)\\033\".format(pp, i))\n                print(\":{}\\033[1;35;40m{}\\033\".format(i, pii))\n                break\n        p.reverse()\n\n        ptsq = ptsq[1:]\n    set_indx = set([a for a in indxs])\n    set_indx.__len__()\n    li = [a for a in set_indx]\n    li.sort()\n    rli = range(set_indx.__len__())\n\n    dli = dict(zip(li, rli))\n    icc = []\n    for i in indxs:\n        icc.append(dli[i])\n\n    return icc\n\n\ndef get_clusters_(data, labels):\n    \"\"\"\n    :param data: The dataset\n    :param labels: The label for each point in the dataset\n    :return: List[np.ndarray]: A list of arrays where the elements of each array\n    are data points belonging to the label at that ind\n    \"\"\"\n    return [data[np.where(labels == i)] for i in range(np.amax(labels) + 1)]\n\n\nclass DynamicAttrs(type):\n    def __new__(mcs, classname, parents=None, add_object=True, **kwargs):\n\n        parent_set = set()\n\n        if parents is None:\n            add_object = True\n        if add_object:\n            parent_set.add(object)\n        if parents is not None:\n            parent_set.update(parents)\n\n        return type(classname, tuple(parent_set), kwargs)\n\n\ndef _list_or_arr(some, _return_ndarray=True):\n    if isinstance(some, ndarray):\n        if _return_ndarray:\n            return some\n        else:\n            return some.tolist()\n    else:\n        if _return_ndarray:\n            return np.asarray(some)\n        else:\n            return some\n\n\ndef get_index_list(_list):\n    _l = _list_or_arr(_list, False)\n    size = len(_l)\n    return np.arange(size)\n\n\ndef get_index_array(_list, return_ndarray=True):\n    arr = _list_or_arr(_list, True)\n    shape = copy.deepcopy(arr.shape)\n\n    size = np.size(arr.flatten())\n\n    index_arr = np.arange(size).reshape(shape)\n    if return_ndarray:\n        return index_arr\n    else:\n        return index_arr.tolist()\n\n\ndef halfsum(lst, halfs=6000):\n    a = [0] * (halfs + 1)\n    a[0] = -1\n    best = halfs + 1\n    for l in lst:\n        for i in range(halfs, l - 1, -1):\n            if (a[i - l] != 0) and a[i] == 0:\n                a[i] = l\n                best = min(halfs - i, best)\n    id = halfs - best\n    b = []\n    while (id > 0):\n        b.append(a[id])\n        id = id - a[id]\n    return b\n\n\ndef line_nest(lst_, halfs):\n    for i, item in enumerate(lst_):\n        if item > halfs:\n            print(f'! value is most halfs {item} {halfs}\\n auto replace {item} -> {halfs} ')\n            lst_[i] = halfs\n    ls = copy.deepcopy(lst_)\n    result = []\n    ost = 0\n    while len(ls) > 0:\n\n        hs = halfsum(ls, halfs)\n        print(hs, sum(hs))\n        ost += halfs - sum(hs)\n        result.append(hs)\n        for item in hs:\n            ls.remove(item)\n        print(len(ls))\n    return result, ost\n\n\ndef conc(*datas):\n    return np.c_[datas], np.asarray(list(map(lambda x: len(x.T), datas)))\n\n\n\"\"\"planes = [\n    [-0.7070897228208075, 0.7071237039189138, 0.00043730674572993943, -290.92373799967623],\n    [0.7073591552420904, -0.7068542257852676, -0.00035914440886667054, 284.52671035465465],\n    [0.7091583588299021, 0.7049927065615538, -0.008927810296750669, -495.7036010715342]]\n\nplane_points=[]\nplane_colors=[]\nfor j in planes:\n    plane_points.append(plane_to_pt(j))\n    plane_colors.append(plane_to_color_(j))\n\nprint(plane_points)\nprint(plane_colors)\n\n\n\ndef get_rh_model():\n    pass\n\n\n\nwith o3d.utility.VerbosityContextManager(\n            o3d.utility.VerbosityLevel.Debug) as cm:\n        mesh, densities = o3d.geometry.TriangleMesh.create_from_point_cloud_poisson(\n        pcd, depth=9)\n    print(mesh)\n    o3d.visualization.draw_geometries([mesh])\n    draw_result(planes, colors)\n\nif __name__ == \"__main__\":\n\n    data = {}\n    point_filee = [\"D:/testptcld/atom-005.e57\", \"D:/testptcld/atom-006.e57\"]\n    for pf in point_filee:\n        e57 = pye57.E57(pf)\n\n        dt = e57.read_scan(0, ignore_missing_fields=True)\n        assert isinstance(dt[\"cartesianX\"], np.ndarray)\n        assert isinstance(dt[\"cartesianY\"], np.ndarray)\n        assert isinstance(dt[\"cartesianZ\"], np.ndarray)\n        data |= dt\n\n    x = np.array(data[\"cartesianX\"])\n    y = np.array(data[\"cartesianY\"])\n    z = np.array(data[\"cartesianZ\"])\n    print('xy', x, y)\n    point_file = \"D:/testptcld/\"\n    # generate some neat n times 3 matrix using a variant of sync function\n    #\n    print(x)\n    # mesh_x, mesh_y = np.meshgrid(x, x)\n\n    # print('mesh',x,  mesh_x)\n    # z = np.sinc((np.power(mesh_x, 2) + np.power(mesh_y, 2)))\n\n    # z_norm = (z - z.min()) / (z.max() - z.min())\n    # print(z_norm)\n    xyz = np.zeros((np.size(x), 3))\n    xyz[:, 0] = x\n    xyz[:, 1] = y\n    xyz[:, 2] = z\n    print('xyz')\n    print(xyz)\n    # print(np.reshape(mesh_x, -1), x)\n\n    # Pass xyz to Open3D.o3d.geometry.PointCloud and visualize\n    pcd = o3d.geometry.PointCloud()\n    pcd.points = o3d.utility.Vector3dVector(xyz)\n    o3d.io.write_point_cloud(f'{point_file}sync.ply', pcd)\n\n    # Load saved point cloud and visualize it\n    pcd_load = o3d.io.read_point_cloud(f'{point_file}sync.ply')\n    # o3d.visualization.draw_geometries([pcd_load])\n\n    print(\"Downsample the point cloud with a voxel of 0.05\")\n    downpcd = pcd_load.voxel_down_sample(voxel_size=0.5)\n    # o3d.visualization.draw_geometries([downpcd])\n    # normal colors 9\n    print(\"Recompute the normal of the downsampled point cloud\")\n    downpcd.estimate_normals(\n        search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=1.0, max_nn=30))\n\n    o3d.visualization.draw_geometries([downpcd], point_show_normal=True)\n\n\n    # convert Open3D.o3d.geometry.PointCloud to numpy array\n    xyz_load = np.asarray(pcd_load.points)\n    print('xyz_load')\n    print(xyz_load)\n\n    # save z_norm as an image (change [0,1] range to [0,255] range with uint8 type)\n    img = o3d.geometry.Image((z_norm * 255).astype(np.uint8))\n    o3d.io.write_image(\"../../TestData/sync.png\", img)\n    o3d.visualization.draw_geometries([img])\n\"\"\"\n",
  "language": "python",
  "imports": [
    "rhino3dm"
  ],
  "has_docstring": true
}