{
  "source_url": "https://github.com/houssameehsain/SOS_MDP/blob/9c874d89094f8c3ce6d06aec133679907c4d2245/RhGh_envs/BeadyRing_env.py",
  "repo": "houssameehsain/SOS_MDP",
  "repo_stars": 2,
  "repo_description": "Deep reinforcement learning to solve self-organized settlement growth modeled as Markov decision processes. ",
  "license": "MIT",
  "filepath": "RhGh_envs/BeadyRing_env.py",
  "instruction": "Beady ring env",
  "code": "import random\nfrom math import floor\nimport scriptcontext as sc\nimport ghpythonlib.components as ghcomp\nimport ghpythonlib.treehelpers as th\n\n\nclass BeadyRing_env:\n    def __init__(self):\n        self._carrier_color = 127.5\n        self._house_color = 0\n        self._street_color = 255\n        self._cell_size = 3\n        self._max_row_len = 21\n        self._obs_size = 37\n        self._3d = False\n        self.pad = int(floor(self._obs_size/2))\n        self.max_world_row_len = int(self._max_row_len + 2*self.pad)\n        self.iter = 0\n        \n        # grid world\n        xy_plane = ghcomp.XYPlane(ghcomp.ConstructPoint(0, 0, 0))\n        cell, _ = ghcomp.Rectangle(xy_plane, self._cell_size, self._cell_size, 0)\n        \n        r_max = self._cell_size * self.max_world_row_len\n        move_range = [i for i in range(0, r_max, self._cell_size)]\n        \n        y_vec = ghcomp.UnitY(move_range)\n        cell_col, _ = ghcomp.Move(cell, y_vec)\n        \n        x_vec = ghcomp.UnitX(move_range)\n        grid_world = []\n        for c in cell_col:\n            cell_row, _ = ghcomp.Move(c, x_vec)\n            grid_world.append(cell_row)\n        \n        self.grid_world = ghcomp.ReverseList(grid_world)\n        \n        # initial location\n        self.R = int(floor(self.max_world_row_len/2))\n        self.C = int(floor(self.max_world_row_len/2))\n        \n        R_space = [r for r in range(int(self.pad), int(self._max_row_len + self.pad))]\n        C_space = [c for c in range(int(self.pad), int(self._max_row_len + self.pad))]\n        self.RC_space = [[[r, c] for c in C_space] for r in R_space]\n        \n        self.x = self.R - self.pad\n        self.y = self.C - self.pad\n        \n        self.cell = [[self.x, self.y], [self.R, self.C]]\n        self.adjacent_cells = [[[self.x, self.y], [self.R, self.C]]]\n        self.adj_cells = [[[self.x, self.y], [self.R, self.C]]]\n        \n        # initial state\n        self.state = [[self._carrier_color for _ in range(int(self.max_world_row_len))] \n                        for _ in range(int(self.max_world_row_len))]\n        \n        # initial observation\n        self.observation = self.get_obs()\n\n    def step(self, _cell_state):\n        self.iter += 1\n        # update state step\n        self.state[self.R][self.C] = 255*_cell_state\n        \n        for i, a in enumerate(self.adj_cells):\n            if a == self.cell:\n                del self.adj_cells[i]\n        \n        adjacent = self.get_adjacent()\n        \n        # reward\n        reward = 0\n        adj_street_count = 0\n        \n        for a in adjacent:\n            if int(self.state[a[1][0]][a[1][1]]) == 255:\n                adj_street_count += 1\n        \n        if _cell_state == 1:\n            if adj_street_count >= 3:\n                reward -= 1\n            elif adj_street_count == 0:\n                reward -= 1\n            elif 0 < adj_street_count < 3:\n                reward += 1\n        elif _cell_state == 0:\n            # density metric\n            reward += 1/(self._max_row_len**2)\n            if adj_street_count == 0:\n                reward -= 1\n            elif adj_street_count >= 3:\n                reward -= 1\n            elif 0 < adj_street_count < 3:\n                reward += 2\n        \n        for item in adjacent:\n            if item not in self.adjacent_cells:\n                self.adjacent_cells.append(item)\n                self.adj_cells.append(item)\n        \n        # done\n        done = False\n        if len(self.adj_cells) == 0:\n            done = True\n        elif len(self.adj_cells) > 0:\n            # next action location selection\n            self.cell = random.choice(self.adj_cells)\n            \n            self.x = self.cell[0][0]\n            self.y = self.cell[0][1]\n            \n            self.R = self.cell[1][0]\n            self.C = self.cell[1][1]\n        \n        # observation\n        self.observation = self.get_obs()\n        \n        return self.observation, reward, done, {}\n\n    def reset(self):\n        # initial state\n        self.state = [[self._carrier_color for _ in range(int(self.max_world_row_len))] \n                        for _ in range(int(self.max_world_row_len))]\n        \n        # reset step counter\n        self.iter = 0\n        \n        # initial location\n        self.R = int(floor(self.max_world_row_len/2))\n        self.C = int(floor(self.max_world_row_len/2))\n        \n        self.x = self.R - self.pad\n        self.y = self.C - self.pad\n        \n        self.cell = [[self.x, self.y], [self.R, self.C]]\n        self.adjacent_cells = [[[self.x, self.y], [self.R, self.C]]]\n        self.adj_cells = [[[self.x, self.y], [self.R, self.C]]]\n        \n        # initial observation\n        self.observation = self.get_obs()\n        \n        return self.observation\n\n    def render(self):\n        # state visualization\n        color_state = [ghcomp.ColourRGB(255, self.state[i], self.state[i], \n                        self.state[i]) for i in range(self.max_world_row_len)]\n        \n        # observation grid\n        left_up_R = int(self.R - self.pad)\n        left_up_C = int(self.C - self.pad)\n        right_bottom_R = int(self.R + self.pad)\n        right_bottom_C = int(self.C + self.pad)\n        obs_grid_ = []\n        for i in range(left_up_R, right_bottom_R + 1):\n            obs_grid_.append(self.grid_world[i][left_up_C : right_bottom_C + 1])\n        \n        return color_state, obs_grid_\n\n    def get_obs(self):\n        # observation\n        left_up_R = int(self.R - self.pad)\n        left_up_C = int(self.C - self.pad)\n        right_bottom_R = int(self.R + self.pad)\n        right_bottom_C = int(self.C + self.pad)\n        obs_ = []\n        for i in range(left_up_R, right_bottom_R + 1):\n            obs_row = []\n            for j in range(left_up_C, right_bottom_C + 1):\n                item = self.state[i][j]\n                obs_row.append(item)\n            obs_.append(obs_row)\n        return obs_\n\n    def get_adjacent(self):\n        # von Neumann neighbourhood\n        adjacent = []\n        if self.x < len(self.RC_space) - 1:\n            adjacent.append([[self.x+1, self.y], self.RC_space[self.x+1][self.y]])\n        if self.y > 0:\n            adjacent.append([[self.x, self.y-1], self.RC_space[self.x][self.y-1]])\n        if self.x > 0:\n            adjacent.append([[self.x-1, self.y], self.RC_space[self.x-1][self.y]])\n        if self.y < len(self.RC_space[self.x]) - 1:\n            adjacent.append([[self.x, self.y+1], self.RC_space[self.x][self.y+1]])\n        return adjacent\n\n    def get_house_cells(self):\n        ## house cells\n        house_cells_ = []\n        for i in range(self.max_world_row_len):\n            for j in range(self.max_world_row_len):\n                if self.state[i][j] == 0:\n                    house_cells_.append(self.grid_world[i][j])\n        return house_cells_\n\nif 'env' not in globals():\n    env = BeadyRing_env()\n    sc.sticky['env'] = env\n\nif reset:\n    observation = sc.sticky['env'].reset()\n    reward = None\n    done = False\n    info = {}\n    \nelif action is not None:\n    observation, reward, done, info = sc.sticky['env'].step(action)\n    \nelse:\n    raise RuntimeError(\"Either reset or action must be provided\")\n\nif render:\n    grid_world_ = th.list_to_tree(sc.sticky['env'].grid_world, source=[0,0])\n    color_state, obs_grid = sc.sticky['env'].render()\n    color_state_ = th.list_to_tree(color_state, source=[0,0])\n    obs_grid_ = th.list_to_tree(obs_grid, source=[0,0])\n    if sc.sticky['env']._3d:\n        house_cells = sc.sticky['env'].get_house_cells()\n        house_cells_ = th.list_to_tree(house_cells, source=[0,0])\n\nsc.sticky[\"observation\"] = observation\nsc.sticky[\"reward\"] = reward\nsc.sticky[\"done\"] = done\nsc.sticky[\"info\"] = info\n\n\n",
  "language": "python",
  "imports": [
    "ghpythonlib",
    "scriptcontext"
  ],
  "has_docstring": false
}