{
  "source_url": "https://github.com/houssameehsain/SOS_MDP/blob/9c874d89094f8c3ce6d06aec133679907c4d2245/RhGh_envs/BeadyRing_fullObs_env.py",
  "repo": "houssameehsain/SOS_MDP",
  "repo_stars": 2,
  "repo_description": "Deep reinforcement learning to solve self-organized settlement growth modeled as Markov decision processes. ",
  "license": "MIT",
  "filepath": "RhGh_envs/BeadyRing_fullObs_env.py",
  "instruction": "Beady ring full obs env",
  "code": "import random\nfrom math import floor\nimport scriptcontext as sc\nimport ghpythonlib.components as ghcomp\nimport ghpythonlib.treehelpers as th\n\n\nclass BeadyRing_env:\n    def __init__(self):\n        self._carrier_color = 127.5\n        self._house_color = 0\n        self._street_color = 255\n        self._cell_size = 3\n        self._max_row_len = 41\n        self._3d = False\n        self.iter = 0\n        \n        # grid world\n        xy_plane = ghcomp.XYPlane(ghcomp.ConstructPoint(0, 0, 0))\n        cell, _ = ghcomp.Rectangle(xy_plane, self._cell_size, self._cell_size, 0)\n        \n        r_max = self._cell_size * self._max_row_len\n        move_range = [i for i in range(0, r_max, self._cell_size)]\n        \n        y_vec = ghcomp.UnitY(move_range)\n        cell_col, _ = ghcomp.Move(cell, y_vec)\n        \n        x_vec = ghcomp.UnitX(move_range)\n        grid_world = []\n        for c in cell_col:\n            cell_row, _ = ghcomp.Move(c, x_vec)\n            grid_world.append(cell_row)\n        \n        self.grid_world = ghcomp.ReverseList(grid_world)\n        \n        # initial location\n        self.R = int(floor(self._max_row_len/2))\n        self.C = int(floor(self._max_row_len/2))\n        \n        R_space = [r for r in range(0, self._max_row_len)]\n        C_space = [c for c in range(0, self._max_row_len)]\n        self.RC_space = [[[r, c] for c in C_space] for r in R_space]\n        \n        self.cell = [self.R, self.C]\n        self.adjacent_cells = [[self.R, self.C]]\n        self.adj_cells = [[self.R, self.C]]\n        \n        # initial state\n        self.state = [[self._carrier_color for _ in range(self._max_row_len)] \n                        for _ in range(self._max_row_len)]\n\n    def step(self, _cell_state):\n        self.iter += 1\n        # update state step\n        self.state[self.R][self.C] = 255*_cell_state\n        \n        for i, a in enumerate(self.adj_cells):\n            if a == self.cell:\n                del self.adj_cells[i]\n        \n        adjacent = self.get_adjacent()\n        \n        # reward\n        reward = 0\n        adj_street_count = 0\n        \n        for a in adjacent:\n            if int(self.state[a[0]][a[1]]) == 255:\n                adj_street_count += 1\n        \n        if _cell_state == 1:\n            if adj_street_count >= 3:\n                reward -= 1\n            elif adj_street_count == 0:\n                reward -= 1\n            elif 0 < adj_street_count < 3:\n                reward += 1\n        elif _cell_state == 0:\n            # density metric\n            reward += 1/(self._max_row_len**2)\n            if adj_street_count == 0:\n                reward -= 1\n            elif adj_street_count >= 3:\n                reward -= 1\n            elif 0 < adj_street_count < 3:\n                reward += 2\n        \n        for item in adjacent:\n            if item not in self.adjacent_cells:\n                self.adjacent_cells.append(item)\n                self.adj_cells.append(item)\n        \n        # done\n        done = False\n        if len(self.adj_cells) == 0:\n            done = True\n        elif len(self.adj_cells) > 0:\n            # next action location selection\n            self.cell = random.choice(self.adj_cells)\n            self.R = self.cell[0]\n            self.C = self.cell[1]\n        \n        return self.state, reward, done, {}\n\n    def reset(self):\n        # initial state\n        self.state = [[self._carrier_color for _ in range(self._max_row_len)] \n                        for _ in range(self._max_row_len)]\n        \n        # reset step counter\n        self.iter = 0\n        \n        # initial location\n        self.R = int(floor(self._max_row_len/2))\n        self.C = int(floor(self._max_row_len/2))\n        \n        self.cell = [self.R, self.C]\n        self.adjacent_cells = [[self.R, self.C]]\n        self.adj_cells = [[self.R, self.C]]\n        \n        return self.state\n\n    def render(self):\n        # state visualization\n        color_state = [ghcomp.ColourRGB(255, self.state[i], self.state[i], \n                        self.state[i]) for i in range(self._max_row_len)]\n        return color_state\n\n    def get_adjacent(self):\n        adjacent = []\n        if self.R < len(self.RC_space) - 1:\n            adjacent.append(self.RC_space[self.R+1][self.C])\n        if self.C > 0:\n            adjacent.append(self.RC_space[self.R][self.C-1])\n        if self.R > 0:\n            adjacent.append(self.RC_space[self.R-1][self.C])\n        if self.C < len(self.RC_space[self.R]) - 1:\n            adjacent.append(self.RC_space[self.R][self.C+1])\n        return adjacent\n\n    def get_house_cells(self):\n        ## house cells\n        house_cells_ = []\n        for i in range(self._max_row_len):\n            for j in range(self._max_row_len):\n                if self.state[i][j] == 0:\n                    house_cells_.append(self.grid_world[i][j])\n        return house_cells_\n\nif 'env' not in globals():\n    env = BeadyRing_env()\n    sc.sticky['env'] = env\n\nif reset:\n    state = sc.sticky['env'].reset()\n    reward = None\n    done = False\n    info = {}\n    \nelif action is not None:\n    state, reward, done, info = sc.sticky['env'].step(action)\n\nelse:\n    raise RuntimeError(\"Either reset or action must be provided\")\n\nif render:\n    grid_world_ = th.list_to_tree(sc.sticky['env'].grid_world, source=[0,0])\n    color_state = sc.sticky['env'].render()\n    color_state_ = th.list_to_tree(color_state, source=[0,0])\n    if sc.sticky['env']._3d:\n        house_cells = sc.sticky['env'].get_house_cells()\n        house_cells_ = th.list_to_tree(house_cells, source=[0,0])\n\nsc.sticky[\"state\"] = state\nsc.sticky[\"reward\"] = reward\nsc.sticky[\"done\"] = done\nsc.sticky[\"info\"] = info\n\n\n",
  "language": "python",
  "imports": [
    "ghpythonlib",
    "scriptcontext"
  ],
  "has_docstring": false
}