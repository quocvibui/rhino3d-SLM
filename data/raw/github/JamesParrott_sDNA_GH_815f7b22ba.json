{
  "source_url": "https://github.com/JamesParrott/sDNA_GH/blob/1a3f7114527ad249a838c5f259e69e8226235d4d/src/sDNA_GH/pyshp_wrapper.py",
  "repo": "JamesParrott/sDNA_GH",
  "repo_stars": 7,
  "repo_description": "Spatial Design Network Analysis from sDNA, in Grasshopper and Rhino3D",
  "license": "NOASSERTION",
  "filepath": "src/sDNA_GH/pyshp_wrapper.py",
  "instruction": "MIT License",
  "code": "#! /usr/bin/python\n# -*- coding: utf-8 -*-\n\n# MIT License\n\n# Copyright (c) [2021] [Cardiff University, a body incorporated\n# by Royal Charter and a registered charity (number:\n# 1136855) whose administrative offices are at 7th floor 30-\n# 36 Newport Road, University CF24 0DE, Wales, UK]\n\n# Permission is hereby granted, free of charge, to any person obtaining a copy\n# of this software and associated documentation files (the \"Software\"), to deal\n# in the Software without restriction, including without limitation the rights\n# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n# copies of the Software, and to permit persons to whom the Software is\n# furnished to do so, subject to the following conditions:\n\n# The above copyright notice and this permission notice shall be included in all\n# copies or substantial portions of the Software.\n\n# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n# SOFTWARE.\n\n\n__authors__ = {'James Parrott', 'Crispin Cooper', 'Fan Zitian'}\n__version__ = '3.0.5'\n\"\"\" Reads .shp files, and parses data and writes .shp files from any iterable.   \n\"\"\"\n\nimport os\nimport abc\nimport re\nimport logging\nimport warnings\nimport itertools\nimport locale\nfrom collections import OrderedDict\nfrom datetime import date\nimport collections\n\nif hasattr(collections, 'Iterable'):\n    Iterable, Callable = collections.Iterable, collections.Callable\nelse:\n    import collections.abc\n    Iterable, Callable = collections.abc.Iterable, collections.abc.Callable\n\nif hasattr(abc, 'ABC'):\n    ABC = abc.ABC\nelse:\n    class ABC(object):\n        __metaclass__ = abc.ABCMeta\n\n\n\n\nimport shapefile as shp\n\nfrom .options_manager import isnamedtuple\nfrom .skel.tools.helpers import funcs\n\n\ntry:\n    basestring #type: ignore\nexcept NameError:\n    basestring = str              \n\nlogger = logging.getLogger(__name__)\nlogger.addHandler(logging.NullHandler())\n\n\nfile_name_no_ext = os.path.splitext(os.path.basename(__file__))[0]\n\n\n\n\n\n\n\nSHP_FIELD_CODES = {int: 'N'\n                  ,float: 'F'\n                  ,bool: 'L'\n                  ,str: 'C'\n                  ,date: 'D'\n                  ,'M': 'M'\n                  }\n                \n\n# int = 'N'  here.  In PyShp, 'N' can also be a float \n\npyshp_writer_method = dict(NULL = 'null'\n                          ,POINT = 'point'\n                          ,MULTIPATCH = 'multipatch'\n                          ,POLYLINE = 'line'\n                          ,POLYGON = 'poly'\n                          ,MULTIPOINT = 'multipoint'\n                          ,POINTZ = 'pointz'\n                          ,POLYLINEZ = 'linez'\n                          ,POLYGONZ = 'polyz'\n                          ,MULTIPOINTZ = 'multipointz'\n                          ,POINTM = 'pointm'\n                          ,POLYLINEM = 'linem'\n                          ,POLYGONM = 'polym'\n                          ,MULTIPOINTM = 'multipointm'\n                          )    # should be the same as val names in shp.shapefile.SHAPETYPE_LOOKUP.values()\n\n\nif hasattr(shp, 'SHAPETYPE_LOOKUP'): \n# SHAPETYPE_LOOKUP not in older versions of shapefile.py \n# (especially 1.2.12 from Hiteca's GHshp)\n    shp_vals = set(shp.SHAPETYPE_LOOKUP.values())\n    pyshp_wrapper_shapes = set(pyshp_writer_method.keys())\n    if shp_vals > pyshp_wrapper_shapes:\n        msg = 'pyshp supports shape(s) '\n        msg += str(shp_vals - pyshp_wrapper_shapes) \n        msg += ' not supported by pyshp_wrapper'\n        logger.warning(msg)\n    elif shp_vals < pyshp_wrapper_shapes:\n        msg = 'pyshp_wrapper supports shape(s) '\n        msg += str(shp_vals - pyshp_wrapper_shapes) \n        msg += ' not supported by pyshp'\n        logger.warning(msg)\n\n\nclass CoerceAndGetCodeOptions(object):\n    decimal = True\n    precision = 12\n    max_dp = 4 # decimal places\n    yyyy_mm_dd = False\n    keep_floats = True\n    use_memo = False # Use the 'M' field code in Shapefiles for un-coerced data\n\n\ndef coerce_and_get_type(x, options = CoerceAndGetCodeOptions):\n    #type coercer function\n\n    if options.decimal:\n        import decimal as dec\n    x = str(x)  # To convert False to 'False' and 0 to '0'\n    dec.getcontext().prec = options.precision #if else options.precision    # significant figures,  >= # decimal places\n    if  x.lower() in ['true','false']:   \n        return x, bool  # i.e. 'L'\n    try:\n        y = int(x)   # if isinstance(x,int):  # Bool test needs to come before this as int(True) == 1\n        return y, int    # i.e.   'N'\n    except ValueError:\n        try:\n            n = options.max_dp\n            if options.decimal:\n                y = dec.Decimal(x)\n                y = y.quantize(  dec.Decimal('.'*int( bool(n) ) + '0'*(n-1) + '1')  )   # e.g. '1' if n=0, else '0.000... (#n 0s) ...0001'\n            else:\n                y = float(x)   \n                \n                # float('12345' ) == 12345.0 so int test needs to come \n                # before this if 'N' and 'F' are utilised differently\n                \n                y = round(y, n)  \n                #  Beware:  \n                # https://docs.python.org/2.7/tutorial/floatingpoint.html#tut-fp-issues                                                      \n                \n            return x if options.keep_floats else y, float\n                    # Tuple , binds to result of ternary operator\n        except (dec.InvalidOperation, ValueError):\n            if isinstance(x, date):\n                return x, date   # i.e. 'D'   \n\n            if isinstance(x, list) and len(x) == 3 and all(isinstance(z, int) for z in x):\n                x = ':'.join(map(str, x))\n    \n            if isinstance(x, basestring):\n                year=r'([0-3]?\\d{3})|\\d{2}'\n                month=r'([0]?\\d)|(1[0-2])'\n                day=r'([0-2]?\\d)|(3[01])'\n                sep=r'([-\\.,:/ \\\\])' # allows different seps r'(?P<sep>[-.,:\\\\/ ])'\n                test_patterns =  [ year + sep + month + sep + day ]   # datetime.date requires yyyy, mm, dd\n                if not options.yyyy_mm_dd:\n                    test_patterns += [  day + sep + month + sep + year   # https://en.wikipedia.org/wiki/Date_format_by_country\n                                       ,month + sep + day + sep + year]  # \n                if any(re.match(pattern, x) for pattern in test_patterns):\n                    return x, date          # TODO, optionally, return datetime.date() object?\n                else:\n                    return x, str  # i.e. 'C'  \n            else:\n                msg = 'Failed to coerce UserText to PyShp record data type.  '\n                if options.use_memo:\n                    logger.warning(msg + 'Using Memo.  ')\n                    return str(x), 'M'\n                else:\n                    logger.error(msg)\n                    raise TypeError(msg)\n\n\nclass LocaleOptions(object):\n    locale = ''  # '' => User's own settings.  \n\n\n\ndef dec_places_req(x, options = LocaleOptions):\n    #type(Number, type[any]) -> int\n    locale.setlocale(locale.LC_ALL,  options.locale)\n    radix_char = locale.localeconv()['decimal_point']\n    fractional_part = str(x).rpartition(radix_char)[2]\n    return len(fractional_part)\n\n\nclass GetFileNameOptions(object):\n    overwrite_shp = True\n    max_new_files = 20\n    suppress_warning = True     \n    duplicate_suffix ='_({number})'\n\ndef get_filename(f, options = GetFileNameOptions):\n    #type: (str, type[any]) -> str\n\n    i = 1\n    prev_f = f\n    file_dir, full_file_name = os.path.split(f)   \n    [file_name, file_extension] = os.path.splitext(full_file_name) \n    while os.path.isfile(f) and i <= options.max_new_files:\n        prev_f = f\n        f = os.path.join(file_dir\n                        ,(file_name\n                         +options.duplicate_suffix.format(number = str(i))\n                         +file_extension\n                         )\n                        ) \n        i += 1\n    if not options.overwrite_shp:\n        if options.max_new_files < i:\n            # If the while loop never found an f that is not a file\n            logger.warning('max_new_files == %s exceeded, Overwriting file: %s' \n                          %(options.max_new_files, f)\n                          )\n        return f\n    elif not options.suppress_warning:\n        logger.warning('Overwriting file: %s ! ' % prev_f)\n    return prev_f\n\n\nclass EnsureCorrectOptions(CoerceAndGetCodeOptions):\n    # ensure_correct & write_iterable_to_shp\n    encoding = 'utf-8' # also used by get_fields_recs_and_shapes\n\ndef len_bytes(x, options = EnsureCorrectOptions):\n    #type(type[any], type[any]) -> int\n    if isinstance(x, str):\n        return len(x.encode(options.encoding))\n    \n    # assume non-ascii unicode characters don't show up in str\n    # of bools, ints, floats, decimals or dates\n    return len(str(x))\n\n\nclass FieldInfo(object):\n    name = None\n    size_req = 1\n    longest_val = None\n    fieldType = str\n    decimal = 0\n\n\n    def field_kwargs_dict(self):\n        \n        retval = dict(size = self.size_req\n                     ,fieldType = SHP_FIELD_CODES[self.fieldType]\n                     )\n        \n        if self.fieldType is float:\n            retval['decimal'] = self.decimal\n\n        return retval\n\n    def increase_size_req_to(self, size, for_val = None):\n        if size <= self.size_req:\n            return\n\n\n        if size >= 256:\n            raise ValueError('Field: %s size attempted to be increased for value: %s' % (self.name, for_val)\n                            +'to width: %s.' % for_val['size']\n                            +'Set min_sizes = False and field_size <= 255 or use smaller data.\\n\\n'\n                            +'Shapefile field lengths can have a maximum width of 255 bytes. '\n                            +'(note in many encodings, e.g. UTF8, more than one byte may be '\n                            +'required per character for unicode strings). '\n                            )\n        \n        \n        self.longest_val = for_val\n        self.size_req = size\n\n    def increase_size_req_for(self, value):\n        size = len_bytes(value, self.options)\n        self.increase_size_req_to(size, for_val = value)\n    \n    def increase_decimal_req_to(self, decimal, for_val = None):\n        if decimal <= self.decimal:\n            return\n\n\n        if decimal + 2 > self.size_req:\n            raise ValueError('shapefile.Writer.field(%s, **kwargs), kwargs = %s' % (self.name, for_val)\n                            +'(size req: %s ).' % self.size_req\n                            +'attempted to create field with decimal places: %s.' % decimal\n                            +'Set min_sizes = False and num_dp <= %s or use smaller data.\\n' % (self.size_req - 2)\n                            )\n        \n        \n        self.longest_val = for_val\n        self.decimal = decimal\n\n    def increase_decimal_req_for(self, value):\n        self.increase_decimal_req_to(dec_places_req(value), for_val = value)\n\n    def update_field(self, fieldType, size = 1, decimal = 0, value = None):\n        self.fieldType = fieldType\n        \n        if fieldType is bool:\n            return\n\n        if size >= self.size_req + 1:\n            self.increase_size_req_to(size, for_val = value)\n        elif value is not None:\n            self.increase_size_req_for(value)\n        elif fieldType is float and decimal >= 1:\n            self.increase_size_req_to(decimal+2, for_val = value)\n\n        if fieldType is float:\n            if decimal >= 1:\n                self.increase_decimal_req_to(decimal, for_val = value)\n            elif value is not None:\n                self.increase_decimal_req_for(value)\n\n    def __init__(self\n                ,name\n                ,value\n                ,fieldType\n                ,decimal = 0\n                ,size = 1\n                ,options = EnsureCorrectOptions\n                ):\n        self.name = name\n        self.options = options\n\n        self.update_field(fieldType, size, decimal, value)\n\n\n\ndef ensure_correct(fields\n                  ,nice_key\n                  ,value\n                  ,val_type\n                  ,attribute_tables\n                  ,options = EnsureCorrectOptions\n                  ): \n    # type(dict, str, type[any], str, dict namedtuple) -> None\n    if nice_key in fields:\n        field_info = fields[nice_key]\n        field_info.increase_size_req_for(value)\n            \n        if val_type is float and field_info.fieldType is float:\n            field_info.increase_decimal_req_for(value) \n\n        if val_type is not field_info.fieldType:\n            if (val_type in (int, float) and\n                field_info.fieldType is bool):\n                #\n                field_info.update_field(fieldType=val_type, value = value)\n            elif (val_type is bool and\n                  field_info.fieldType is int and\n                  all(attribute_tables[i][nice_key] in [0,1] \n                      for i in attribute_tables)):\n                #\n                field_info.update_field(fieldType=bool, value = value)\n                #1s and 0s are in a Boolean field as integers or a 1 or a 0 \n                # in a Boolean field is type checking as an integer\n                # TODO:  Check options and rectify - flag as Bool for now \n                #        (rest of loop will recheck others), \n                #        or flag for recheck all at end\n            elif (val_type is float\n                  and field_info.fieldType is int):\n                field_info.update_field(fieldType = float, value = value)  \n            else:\n                field_info.update_field(fieldType = str)\n                #logger.error('Type mismatch in same field.  Cannot store ' \n                #            +str(value) + ' as .shp record type ' \n                #            + fields[nice_key]['fieldType']\n                #            )\n    else:\n        fields[nice_key] = FieldInfo(name = nice_key\n                                    ,size = len_bytes(value, options)\n                                    ,value = value\n                                    ,fieldType = val_type\n                                    ,options = options\n                                    )   \n        # print('len_bytes(value, options): %s' % len_bytes(value, options))                 \n        # could add a 'name' field, to save looping over the keys to this\n        # dict:\n        # fields[nice_key][name] = nice_key\n        #  and then just unpack a fields dict for each one:\n        # shapefile.Writer.field(**fields[nice_key]).  \n        # But it seems to be\n        # an undocumented feature of Writer.fields, doesn't reduce the amount\n        #  of code (actually needs an extra line), requires duplicate data \n        # in fields.  If we wanted to rename it in the shape file to\n        # something different than the dictionary key then this is a neat way \n        # of doing so.\n\n    # Mutates fields.  Nothing returned.\n\n\nclass WriteIterableToShpOptions(EnsureCorrectOptions):\n    field_size = 30\n    cache_iterable= False\n    uuid_field = 'Rhino3D_' # 'object_identifier_UUID_'     \n    uuid_length = 36 # 32 in 5 blocks (2 x 6 & 2 x 5) with 4 separator characters.\n    num_dp = 10 # decimal places\n    min_sizes = True\n\n\ndef write_iterable_to_shp(my_iterable \n                         ,shp_file_path\n                         ,is_shape \n                         ,shape_mangler\n                         ,shape_IDer # to make dict key\n                         ,key_finder\n                         ,key_matcher\n                         ,value_demangler\n                         ,shape_code # e.g. 'POLYLINEZ'\n                         ,options = WriteIterableToShpOptions\n                         ,field_names = None\n                         ,AttributeTablesClass = None\n                         ):\n    #type(type[Iterable]\n    #    ,str\n    #    ,function\n    #    ,function\n    #    ,function\n    #    ,function\n    #    ,function\n    #    ,function\n    #    ,str\n    #    ,namedtuple\n    #    ,dict\n    #    )  -> int, str, dict, list, list\n    #\n    is_iterable = isinstance(my_iterable, Iterable)\n    is_str = isinstance(my_iterable, basestring)\n    is_path_str = isinstance(shp_file_path, basestring)\n\n\n    if ((not is_iterable) \n        or is_str \n        or not is_path_str\n        or not os.path.isdir(os.path.dirname(shp_file_path))):\n        #\n        logger.error ('returning.  Not writing to .shp file')\n        msg_1 = ' Is Iterable == %s' % is_iterable\n        logger.info (msg_1)\n        msg_2 = ' Is my_iterable str == %s' % is_str\n        logger.info (msg_2)\n        msg_3 = ' Is path str == %s' % is_path_str\n        logger.info (msg_3)\n        msg_4 = 'my_iterable == %s ' % my_iterable\n        logger.info(msg_4)\n        \n        try:\n            msg_5 = (' Is path path == %s ' \n                    % os.path.isdir( os.path.dirname(shp_file_path))\n                    )\n            logger.info (msg_5)\n        except TypeError:\n            msg_5 = 'Invalid path type == %s ' % shp_file_path\n        logger.info ('Path == %s' %shp_file_path)\n        msg = '\\n'.join([msg_1, msg_1, msg_3, msg_4, msg_5])\n        raise TypeError(msg)\n        \n\n\n    fields = OrderedDict( {options.uuid_field : FieldInfo(name = options.uuid_field\n                                                         ,value = None\n                                                         ,size = options.uuid_length\n                                                         ,fieldType = str\n                                                         ,options = options\n                                                         )\n                          }\n                         )\n    \n    if AttributeTablesClass is None:\n        attribute_tables = OrderedDict()\n    else:\n        attribute_tables = AttributeTablesClass()\n\n    if True: #field_names is None or options.cache_iterable: \n        \n        for item in my_iterable:    \n            keys = key_finder(item) # e.g. rhinoscriptsyntax.GetUserText(item,None)\n            values = OrderedDict( {options.uuid_field : shape_IDer(item) } )   \n            for key in keys:\n                # Demangle and cache the user text keys and values\n                nice_match = key_matcher(key)            \n                if nice_match:\n                    nice_key = nice_match.group('name')\n                    #TODO: Support more fields, e.g. type, size\n                    value = value_demangler(item, key) \n\n                    value, val_type = coerce_and_get_type(value, options)\n                    values[nice_key] = value \n\n\n                    # Update the shp field sizes if they aren't big enough or the field is new, and type check\n                    if options.min_sizes:\n                        ensure_correct(fields, nice_key, value, val_type, attribute_tables, options)\n                        # mutates fields, adding nice_key to it if not already there, else updating its val\n                    else:\n                        fields[nice_key] = FieldInfo(name = nice_key\n                                                    ,size = options.field_size\n                                                    ,value = value\n                                                    ,fieldType = val_type\n                                                    ,decimal = options.num_dp\n                                                    ,options = options\n                                                    )  \n            attribute_tables[item] = values.copy()  # item may not be hashable so can't use dict of dicts\n        \n    else:\n        for name in field_names:\n            fields[name] = dict(size = options.field_size\n                               ,fieldType = SHP_FIELD_CODES[str]\n                               )\n        #TODO setup basic fields dict from list without looping over my_iterable        \n\n\n\n    def default_record_dict(item):\n        retval = { key_matcher(key).group('name') : \n                         str( value_demangler(item, key) )[:options.field_size] \n                            for key in key_finder(item) \n                            if (key_matcher(key) and\n                                key_matcher(key).group('name') in fields\n                               )\n                 }\n        retval[options.uuid_field ] = shape_IDer(item)\n        return retval\n\n\n    shapefile_path = get_filename(shp_file_path\n                                 ,options\n                                 )\n       \n\n\n\n    \n    with shp.Writer(os.path.normpath(shapefile_path)\n                   ,getattr(shp, shape_code)\n                   ,encoding = options.encoding\n                   ) as w:\n\n        for key, val in fields.items():\n            \n            if val.size_req >= 256:\n                raise ValueError('shapefile.Writer.field(%s, **kwargs), kwargs = %s' % (key, val)\n                                +'attempted to create field of width: %s.' % val['size']\n                                +'Set min_sizes = False and field_size <= 255 or use smaller data.\\n'\n                                +'Shapefile field lengths can have a maximum width of 255 bytes. '\n                                +'(note in many encodings, e.g. UTF8, more than one byte may be '\n                                +'required per character for unicode strings). '\n                                )\n            w.field(key, **val.field_kwargs_dict())\n        #w.field('Name', 'C')\n\n\n        add_geometric_object = getattr(w,  pyshp_writer_method[shape_code])\n        # e.g. add_geometric_object = w.linez\n\n        for shape, attribute_table in attribute_tables.items():\n            if not is_shape(shape, shape_code):\n                msg = 'Shape: %s cannot be converted to shape_code: %s' \n                msg %= (shape, shape_code)\n                logger.error(msg)\n                raise TypeError(msg)\n\n            list_of_shapes = shape_mangler(shape)\n            if list_of_shapes:\n\n                add_geometric_object(list_of_shapes) \n                #e.g. w.linez(list_of_shapes)  \n\n                w.record(**attribute_table)    \n\n\n\n    return 0, shapefile_path, fields, attribute_tables\n\n\nclass FieldRecsShapesOptions(object):\n    encoding = 'utf-8'\n\n\ndef get_fields_recs_and_shapes(shapefile_path, options = FieldRecsShapesOptions):\n    # type(str, type[any]) -> list, Generator[dict], Generator[type[any]], list[Number], str, int\n    with shp.Reader(shapefile_path, encoding = options.encoding) as r:\n        fields = r.fields[1:] # skip first field (deletion flag)\n        recs = (record.as_dict() for record in r.iterRecords())\n        shapes = r.iterShapes()\n        bbox = r.bbox\n        shape_type = shp.SHAPETYPE_LOOKUP[r.shapeType]\n        num_entries = len(r)\n\n    #gdm = {shape : {k : v for k,v in zip(fields, rec)} \n    #               for shape, rec in zip(shapes, recs)  }\n    \n    return fields, recs, shapes, bbox, shape_type, num_entries\n\n\ndef shp_meta_data(shapefile_path, options = FieldRecsShapesOptions):\n    # type(str, type[any]) -> list, list[Number], str, int\n    with shp.Reader(shapefile_path, encoding = options.encoding) as r:\n        fields = r.fields[1:] # skip first field (deletion flag)\n        bbox = r.bbox\n        shape_type = shp.SHAPETYPE_LOOKUP[r.shapeType]\n        num_entries = len(r)\n\n    #gdm = {shape : {k : v for k,v in zip(fields, rec)} \n    #               for shape, rec in zip(shapes, recs)  }\n    \n    return fields, bbox, shape_type, num_entries\n\n\ndef delete_file(path\n               ,logger = logger\n               ):\n    #type(str, type[any]) -> None\n    if os.path.isfile(path):\n        logger.info('Deleting file: %s ' % path)\n        # os.remove(path)\n        funcs.recycle_file(path)\n\ndef name_matches(file_name, regexes = ()):\n    #type(str, Iterable) -> bool\n    if isinstance(regexes, basestring):\n        regexes = (regexes,)\n    return any(bool(re.match(regex, file_name)) for regex in regexes)\n\n\ndef delete_shp_files_if_req(f_name\n                           ,logger = logger\n                           ,delete = True\n                           ,strict_no_del = False\n                           ,regexes = () # no file extension in regexes\n                           ):\n    #type(str, type[any], bool, str/tuple) -> None\n    logger.debug('strict_no_del == %s ' % strict_no_del)\n    if strict_no_del:\n        return\n\n    file_name_no_ext = os.path.splitext(f_name)[0]\n    logger.debug('delete == %s ' % delete)\n    if (delete or name_matches(file_name_no_ext, regexes)):\n        for ext in ('.shp', '.dbf', '.shx', '.shp.names.csv'):\n            path = file_name_no_ext + ext\n            delete_file(path, logger)\n\n\nclass ShapeFilesDeleter(ABC):  # ABC for register\n    \n    file_name = None\n\n    def __init__(self\n                ,file_name \n                ):\n        self.file_name = file_name\n\n    def delete_files(self, delete, opts):\n        if isinstance(self.file_name, basestring):\n            #\n            delete_shp_files_if_req(f_name = self.file_name\n                                    ,delete = delete\n                                    ,strict_no_del = opts['options'].strict_no_del  \n                                    )\n\nclass InputFileDeletionOptions(GetFileNameOptions, FieldRecsShapesOptions):\n    del_after_sDNA = True\n    strict_no_del = False \n    INPUT_FILE_DELETER = None\n\nclass OutputFileDeletionOptions(GetFileNameOptions, FieldRecsShapesOptions):\n    strict_no_del = InputFileDeletionOptions.strict_no_del \n    del_after_read = True\n    OUTPUT_FILE_DELETER = None\n\nclass ShapeRecordsOptions(OutputFileDeletionOptions):\n    copy_dicts = False\n    shp_type = 'POLYLINEZ'\n\n\nclass NullDeleter(object):\n    pass\nShapeFilesDeleter.register(NullDeleter)\n#assert issubclass(NullDeleter, ShapeFilesDeleter)\n\n\nclass SizedIterator(object):\n    \"\"\" An wrapper for iterator that knows its own length.\n    \n        Instances can yield the same values as from an iterator\n        from any generator function, but can also be duck-typed \n        for lists and tuples that require a length (but that are \n        still only iterated over, i.e. that don't have __getitem__ \n        or other list methods called on them, such as:\n        ghpythonlib.treehelpers.list_to_tree\n        https://gist.github.com/piac/ef91ac83cb5ee92a1294#file-list_to_tree-py ). \n        \n        Class instances are initialised with any iterator and \n        a length.  The intended usage case is for generator \n        functions, for whom a length may still be known by other \n        trusted means e.g. from reliable file meta-data (or whose \n        value is unimportant as long as it's non-zero).  The iterators \n        returned by generator functions do not have lengths, as such \n        a 'length', the number yield statements executed, depends \n        dynamically on the code in the generator function's body.  \n    \"\"\"\n\n    def __init__(self, iterator, length):\n        self.iterator = iterator\n        self.length = length\n    \n    def next(self):\n        return next(self.iterator)\n    \n    def __iter__(self):\n        return self\n\n    def __len__(self):\n        return self.length\n\n\nclass TmpFileDeletingIterator(SizedIterator):\n    \"\"\" Iterator wrapper for a file object that calls \n        self.close and thence self.maybe_delete_file \n        when the iterator is exhausted.\n\n        This is fine just to safely delete a temporary \n        shape file.  In general there are many issues \n        with this pattern, e.g.\n        if the user breaks out of the for loop early, \n        clean up will not happen automatically for them.  \n        https://peps.python.org/pep-0533/ \n    \"\"\"\n    def __init__(self, reader, opts = None):\n        # type(shp.Reader, dict, dict) -> None\n        if opts is None:\n            opts = dict(options = ShapeRecordsOptions)\n        self.opts = opts\n        \n        if isinstance(reader, basestring) and os.path.isfile(reader):\n            self.file_path = reader\n            encoding = opts['options'].encoding.replace('-','')\n            reader = shp.Reader(reader, encoding = encoding)\n        elif not isinstance(reader, shp.Reader):\n            raise ValueError('No shapefile reader or file path supplied. ')\n\n        self.reader = reader\n        \n        self.file_path = reader.shp.name\n\n        if reader.shapeTypeName != opts['options'].shp_type:\n            msg = 'Shape type of file: %s, %s does not match '\n            msg %= (self.file_path, reader.shapeTypeName)\n            msg += 'shape type in options: %s. '\n            msg %= opts['options'].shp_type\n            msg += \"Using the shape file's shape type. \"\n            \n            logger.warning(msg)\n            warnings.warn(msg)\n            \n            \n        self.shp_type = reader.shapeTypeName\n\n        \n\n        super(TmpFileDeletingIterator, self).__init__(\n                                                   iterator = self.generator()\n                                                  ,length = len(reader)\n                                                  )\n        \n    def generator(self):\n        \"\"\" Generator to process the shp file reader, used to produce the \n            desired iterator that yields what ever is wanted.  \"\"\"\n        return self.reader.iterShapes()\n\n    def next(self):\n        try:\n            retval = next(self.iterator)\n        except StopIteration as e:\n            logger.debug('Iterator exhausted.  Closing...')\n            self.close()\n            raise e\n    \n        return retval\n\n    def maybe_delete_file(self, *args):\n        logger.debug('maybe_delete_file called.')\n        options = self.opts['options']\n        if (options.del_after_read and \n            not options.strict_no_del and \n            not options.overwrite_shp and \n            isinstance(options.OUTPUT_FILE_DELETER, ShapeFilesDeleter) and\n            self.file_path == options.OUTPUT_FILE_DELETER.file_name):\n            #\n            options.OUTPUT_FILE_DELETER.delete_files(\n                                                delete = options.del_after_read\n                                               ,opts = self.opts\n                                               )\n            self.opts['options'] = self.opts['options']._replace(\n                                                    OUTPUT_FILE_DELETER = None\n                                                    )\n\n    def close(self):\n        logger.debug('Closing reader: %s' % self.reader)\n        self.reader.close()\n        logger.debug('Attempting to delete file: %s ' % self.file_path)\n        self.maybe_delete_file()\n\n\ndef is_single_shape(shapeRecord):\n    shape = getattr(shapeRecord, 'shape', shapeRecord)\n    if not hasattr(shape, 'parts'):\n        msg = ('shape has no attr \"parts\", the indices of sub-shapes '\n              +'in shape.points.  Assuming it is a single shape. '\n              )\n        logger.warning(msg)\n        warnings.warn(msg)\n        return True\n    else:\n        return len(shape.parts) <= 1\n\n\nclass TmpFileDeletingRecordsIterator(TmpFileDeletingIterator):\n    \"\"\" If zipping another iterator that is shorter or the same length\n        with this one (e.g. that yields \n        existing shapes), to ensure the temporary file deleter is \n        called when this iterator is used up, be sure to zip it with\n        zip_longest or, izip_longest, make an iterator the same size\n        artificially longer.  Otherwise the file deleter's\n        delete_files method must be called directly.\n    \"\"\"\n    def generator(self):\n        return (record.as_dict() for record in self.reader.iterRecords())\n\n\n\n\nclass MultipleShapes(list):\n    \"\"\" Trivial flag class. \"\"\"\n    pass\n\ndef identity(*args):\n    return args\n\n\ndef clone_dicts(group):\n    return [[(obj, dict_.copy()) for obj, dict_ in list_] for list_ in group]\n\n    \ndef shape_and_rec_as_dict(shape_record):\n    return shape_record.shape, shape_record.record.as_dict()\n\ndef shapes_and_recs_as_dicts(shape_records):\n        return [shape_and_rec_as_dict(shape_record)\n                for shape_record in shape_records\n                ]\n\n\n\nclass TmpFileDeletingShapeRecordsIterator(TmpFileDeletingIterator):\n\n    def is_3D_shape_type(self):\n        #  POLYLINEZ or LINEM etc.\n        return self.reader.shapeTypeName[-1] in 'ZM'\n\n    def points_and_rec_2D(self, shape, record):\n        return shape.points, record\n\n    def points_and_rec_3D(self, shape, record):\n        # z coordinate is not simply in points\n        return [(x,y,z) for ((x,y), z) in zip(shape.points, shape.z)], record\n\n    def points_and_records(self, shapes_and_records):\n        return [self.points_and_rec(shape, record) \n                for shape, record in shapes_and_records]    \n\n    def unpack_multi_shape_entry_repeat_rec_as_dict(self, multi_shape_record):\n        shapes, rec = shape_and_rec_as_dict(multi_shape_record)\n        points, _ = self.points_and_rec(shapes, rec)\n        parts = shapes.parts\n        return ((points[start:end], rec) for start, end in itertools.pairwise(parts))\n\n    def setup_manglers(\n                    self\n                    ,extra_manglers\n                    ,copy_dicts = ShapeRecordsOptions.copy_dicts\n                    ):\n        # manglers will be applied to groups of consecutive single shapes \n        # and groups of consecutive multi-shape shp file entries\n\n\n        self.manglers = {True:  funcs.compose(self.points_and_records, shapes_and_recs_as_dicts)\n                        ,False: self.unpack_multi_shape_entry_repeat_rec_as_dict\n                        }\n\n        if extra_manglers is not None or copy_dicts:\n\n            if extra_manglers is None: # assert copy_dicts\n                extra_manglers = {False : [clone_dicts]}\n            elif copy_dicts:\n                if isinstance(extra_manglers[False], Callable):\n                    extra_manglers[False] = [extra_manglers[False]]\n                extra_manglers[False].insert(0, clone_dicts)\n\n\n            for key, val in extra_manglers.items():\n                new_manglers = [val] if isinstance(val, Callable) else val\n                    \n                if key in self.manglers:\n                    new_manglers += [self.manglers[key]]\n                \n                logger.debug('new_manglers == %s' % (new_manglers,))\n                \n                new_mangler = funcs.compose(*new_manglers)\n                logger.debug('new_mangler == %s' % (new_mangler,))\n\n\n                self.manglers[key] = new_mangler\n\n        for mangler in self.manglers.values():\n            if not isinstance(mangler, Callable):\n                msg = 'mangler == %s not Callable' % (mangler,)\n                logger.error(msg)\n                raise ValueError(msg)\n\n\n    def __init__(self, reader, extra_manglers = None, opts = None):\n        #type(shp.Reader, dict, dict)\n\n        if opts is None:\n            opts = dict(options = ShapeRecordsOptions)\n\n        self.setup_manglers(\n                         extra_manglers\n                        ,copy_dicts = opts['options'].copy_dicts\n                        )\n\n        super(TmpFileDeletingShapeRecordsIterator, self).__init__(reader, opts)\n\n        self.points_and_rec = self.points_and_rec_3D if self.is_3D_shape_type() else self.points_and_rec_2D\n\n\n\n    def generator(self):\n        return funcs.multi_item_unpacking_iterator(\n                                         items = self.reader.iterShapeRecords()\n                                        ,is_single_item = is_single_shape\n                                        ,manglers = self.manglers\n                                        )\n\n\n \n\n\n\n\nclass ShpOptions(ShapeRecordsOptions\n                ,GetFileNameOptions\n                ,WriteIterableToShpOptions\n                ,LocaleOptions\n                ,FieldRecsShapesOptions\n                ):\n    pass\n\n",
  "language": "python",
  "imports": [
    "ghpythonlib",
    "rhinoscriptsyntax"
  ],
  "has_docstring": true
}