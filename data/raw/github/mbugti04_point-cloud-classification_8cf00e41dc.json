{
  "source_url": "https://github.com/mbugti04/point-cloud-classification/blob/0211bf6c70e6f0d8efd18b3ba982292859ef8320/process_3dm_file.py",
  "repo": "mbugti04/point-cloud-classification",
  "repo_stars": 0,
  "repo_description": "Classifying New York City Boroughs with a Point Cloud Transformer",
  "license": "unknown",
  "filepath": "process_3dm_file.py",
  "instruction": "This file is for processing the .3dm file type so that it may be usable. Mainly, it extracts the vertices from the meshes so that they may be used as 'point clouds'. These are saved into .json files. There are also helper functions to return the vertrices from the .json files.",
  "code": "# This file is for processing the .3dm file type so that it may be usable.\n# Mainly, it extracts the vertices from the meshes so that they may be used as 'point clouds'.\n# These are saved into .json files.\n# There are also helper functions to return the vertrices from the .json files.\n\nimport json\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport rhino3dm\nimport torch\nimport torch_geometric.transforms as T\nfrom torch_geometric.transforms import KNNGraph\nfrom torch_geometric.data import Data\nfrom torch_geometric.loader import DataLoader\nimport os\nimport gc\nimport memory_profiler\n\n\n\n# Reads the .3dm file\n# @memory_profiler.profile\ndef load_model(file_name):\n     return rhino3dm.File3dm.Read(file_name)\n\n# Extracts vertices from .3dm model\n# @memory_profiler.profile\ndef process_3dm(model):\n    combined_vertices = []\n    if model is not None:\n        for obj in model.Objects:\n            geometry = obj.Geometry\n            # objects in the NYC dataset are either breps or polylinecurves\n            if isinstance(geometry, rhino3dm.Brep):\n                brep = geometry\n                vertices = [[vertex.Location.X, vertex.Location.Y, vertex.Location.Z] for vertex in brep.Vertices]\n                for vertex in vertices:\n                    combined_vertices.append(vertex)\n    return combined_vertices\n\ndef save_to_json(vertices, file_name):\n    vertices = vertices.tolist()\n    with open(file_name, 'w') as f:\n        json.dump(vertices, f)\n\ndef load_from_json(file_name):\n    try:\n        with open(file_name, 'r') as f:\n            vertices = json.load(f)\n        return vertices\n    except FileNotFoundError:\n        return False\n\n# Labels for the different boroughs\nclasses = [\"MN\", \"BX\", \"BK\", \"QN\", \"SI\"]\n\n# Converts a list of vertices into tensors\n# which can be used for processing in pytorch\ndef vertex_to_data(vertices, label, k=6):\n    data = Data(pos=torch.tensor(vertices, dtype=torch.float), y=torch.tensor([classes.index(label)]))\n    return data\n\ndef get_all_models_from_json(samples=-1):\n    file_directory = \"data\\\\NYC\\\\\"\n\n    models = []\n    for root, dirs, files in os.walk(file_directory):\n        for file_name in files:\n            if file_name.endswith(\".json\"):\n                print(\"Loading vertices from file:\", file_name)\n                with open(os.path.join(root, file_name), 'r') as f:\n                    vertices = json.load(f)\n                    vertices = np.array(vertices)\n\n                if samples != -1:\n                    # if vertices has less than x vertices, pad with zeros\n                    if len(vertices) < samples:\n                        vertices += [[0, 0, 0]] * (samples - len(vertices))\n                    # select x random vertices\n                    vertices = vertices[np.random.choice(vertices.shape[0], samples, replace=False)]\n\n                label = file_name[12:14]\n\n                data = vertex_to_data(vertices, label, k=6)\n                models.append(data)\n    \n    return models\n\n# @memory_profiler.profile\n# This method converts a .3dm file to .json\ndef process_models():\n    # models = []\n    file_directory = \"data\\\\NYC\\\\\"\n\n    for root, dirs, files in os.walk(file_directory):\n        for file_name in files:\n            if file_name.endswith(\".3dm\"):\n                json_file_name = os.path.join(root, file_name[:-4] + \".json\")\n\n                print(\"Obtaining vertices from 3dm file:\", file_name)\n\n                model = load_model(os.path.join(root, file_name))\n                vertices = process_3dm(model)\n                vertices = np.array(vertices)\n\n                del model\n                gc.collect()\n\n                # Boolean to determine if to sample points when saving to file or not.\n                # This saves space but loses information.\n                # It is also possible to save all points but sample them at run-time\n                #   so that you can vary the sample number without redownloading the entire dataset\n                do_sample = False\n                if do_sample:\n                    samples = 8192\n                    # if vertices has less than x vertices, pad with zeros\n                    if len(vertices) < samples:\n                        vertices += [[0, 0, 0]] * (samples - len(vertices))\n                    # select x random vertices\n                    vertices = vertices[np.random.choice(vertices.shape[0], samples, replace=False)]\n                    # vertices = vertices[::100]\n\n\n                save_to_json(vertices, json_file_name)\n\n                # Delete the 3dm file after processing\n                os.remove(os.path.join(root, file_name))",
  "language": "python",
  "imports": [
    "rhino3dm"
  ],
  "has_docstring": true
}