{
  "source_url": "https://github.com/ZacZhangzhuo/3d_printing_teamwork/blob/1ae8e701e83329eb292170fc8bc483fa912b639b/Design_Substructure/Archive/Agents%20Generation/221214_Substructure_khara_working.py",
  "repo": "ZacZhangzhuo/3d_printing_teamwork",
  "repo_stars": 1,
  "repo_description": "This is the 3D Printing teamwork repository of team 4 of MAS dfab 2023",
  "license": "MIT",
  "filepath": "Design_Substructure/Archive/Agents Generation/221214_Substructure_khara_working.py",
  "instruction": "221214 substructure khara working",
  "code": "import Rhino.Geometry as rg\nimport ghpythonlib.treehelpers as th\nimport random\nimport math\nfrom copy import deepcopy\n\n#hellooo\nrandom.seed(seeed)\ntolerance = 0.001\n\n#this class is focused on the properties and methods of each instance MAS (multi agent system)\nclass Environment(object):\n    \n    def __init__(self, u_div, v_div, surface, agents_list = [], repulsion_thresh = 0.5):\n        #self.num_agents = 0    #total number of agents\n        self.u_div = u_div\n        self.v_div = v_div\n        self.surface = surface\n        self.agents = []\n        self.all_agents = []\n        \n\n        self.finished_agents = []\n        if len(agents_list) > 0:\n            self.agents = agents_list\n            self.all_agents = deepcopy(agents_list)\n        self.repulsion_thresh = repulsion_thresh\n        self.strong_agents = self.GenerateStrongAgentsList()\n\n    #this function takes the u values and transform them into agents\n    def populate_agents(self, u_vals, target_factors):\n        # instantiatie all agents\n        for u, t_fac in zip(u_vals,target_factors) :\n            self.agents.append(Agent(u, 0, 0, t_fac / self.v_div,t_fac, self.surface)) \n\n    #generates new agents in the env \n    def populate_sub_agents(self, prev_envs, num_new_agents, shift_up_factor,shift_down_factor, sub_goal_fac):\n        #rememeber to add to the full list of agents\n        sub_agents = []\n        goals=[]\n        all_v = []\n        for env in prev_envs:\n            boundary = env.CalculateBoundaryRegion()\n            all_v.append(boundary[-1])\n            for i in range(num_new_agents):\n                u = Remap(random.random(),0,1, boundary[0], boundary[1])\n                v = Remap(random.random(),0,1, boundary[2], boundary[3])\n                sub_agents.append(Agent(u,v,0,0,0,self.surface)) #pending !!\n\n        #populate each point separately \n        #get the highest value of v \n        print (all_v)\n        all_v.sort()\n        lower_bound_v = all_v[-1]\n        lower_bound_v += shift_up_factor \n        upper_bound_v = 1 - shift_down_factor\n        for sub_agent in sub_agents:\n            sub_agent.isSubAgent = True\n            sub_agent.sub_goal_u = random.random()\n            sub_agent.sub_goal_v = Remap(random.random(), 0, 1, lower_bound_v, upper_bound_v)\n            goals.append(self.surface.PointAt( sub_agent.sub_goal_u, sub_agent.sub_goal_v))\n            raw_du = sub_agent.sub_goal_u - sub_agent.u\n            raw_dv = sub_agent.sub_goal_v - sub_agent.v\n            vector = rg.Vector2d(raw_du, raw_dv)\n            unit_vect = sub_agent.UnitizeEffect(self.u_div, self.v_div, vector)\n            sub_agent.du = sub_goal_fac * unit_vect.X\n            sub_agent.dv = sub_goal_fac * unit_vect.Y\n            self.agents.append(sub_agent)\n            self.all_agents.append(sub_agent)\n        return goals, [agent.pts for agent in sub_agents]\n        \n    \n\n\n\n    def update_agents_pos (self, coherence_rad, coherence_fac, align_rad, align_fac, avoid_rad, avoid_fac, Coherence_T, Alignment_T, Separation_T, sub_goal_rad = 0, sub_goal_fac = 0):\n        # generate the new position of each agent by calculating their new direction and velocity\n        #for each agent apply all the functions on it given the required factors for each parameter\n        #if the agent arrives we pop out this agent from the list and add it to the finished list \n        # add a function that if everything is arrived just stop \n        #list of all effects so as not to change the behaviour of the agents during update\n        effects_list = []\n        for agent in self.agents:\n            #always add a positive up vector in the beginning\n            if agent.isSubAgent:\n                agent.UpdateSubAgentProgress(sub_goal_rad, sub_goal_fac, self.u_div, self.v_div)\n            effects_vector = rg.Vector2d(agent.right_force,agent.up_force)            \n\n            if Coherence_T:\n                coherence_vector = agent.Coherence(coherence_rad, self.agents, self.u_div, self.v_div, coherence_fac)\n                effects_vector += coherence_vector\n\n            if Alignment_T:\n                alignment_vector = agent.Alignment(align_rad, self.agents, self.u_div, self.v_div, align_fac)\n                effects_vector += alignment_vector\n\n            if Separation_T:\n                separation_vector = agent.Separation(avoid_rad, self.agents, self.u_div, self.v_div, avoid_fac)\n                effects_vector += separation_vector\n\n                #sum all of the vectors + the actual du and dv of the agent + unitize --> do nothing but add them to the effects_list\n                effects_list.append(agent.AddTotalEffect(self.u_div, self.v_div, effects_vector))\n\n\n        temp_removed_agents = []\n        for agent, effect in zip(self.agents, effects_list):\n            agent.AgentStep(effect)\n            if agent.arrived:\n                temp_removed_agents.append(agent)\n       \n        for fin_agent in temp_removed_agents:\n            self.finished_agents.append(fin_agent)\n            self.agents.remove(fin_agent)\n\n\n        #pending: function that ensures all agents have reached the final destination\n    #checks all agents in the environment if they are strong or not based on their direction vector\n    def GenerateStrongAgentsList(self):\n        strong_Agents_list = []\n        for agent in self.agents:\n            if agent.unitized_upForce > self.repulsion_thresh:\n                strong_Agents_list.append(agent)\n        return strong_Agents_list\n\n    #from an environment detects the minimum and maximum boundary\n    def CalculateBoundaryRegion(self):\n        all_u = [agent.u for agent in self.agents]\n        all_u.sort()\n\n        all_v = [agent.v for agent in self.agents]\n        all_v.sort()\n\n        return [all_u[0], all_u[-1],all_v[0], all_v[-1]]\n    \n\n            \nclass Agent(object):\n\n#the main parameters are poisiton on the surface, velocity in both directions \n    def __init__(self, u, v, du, dv,unit_dv, surface):\n        self.u = u\n        self.v = v\n        self.surface = surface\n        self.position = self.surface.PointAt(self.u, self.v) ##for the surface\n\n        #save the dv as the constant upward vector for the current agent\n        self.up_force = dv\n\n        self.right_force = 0\n        self.unitized_upForce = unit_dv #unitized value of the up vector\n        #print (self.unitized_upForce)\n        self.du = du\n        self.dv = dv\n        self.pts = []\n        self.pts.append(self.position)\n        self.arrived = False\n\n        self.isSubAgent = False\n        self.sub_goal_u = 0\n        self.sub_goal_v = 0\n\n    def Coherence(self, radius, agents, u_div, v_div, coh_fac):\n        # agents : list of agents in the environment\n        # fx for Coherence\n        \"\"\" \n        --- within the specified radius we need to iterate over each agent apart from ours and do the following:\n        -> calculate the center (u,v) of the surrounding by 2 getting the average over all of the points \n        -> this shall be the point to aim at from the agent position \n        -> unitize the produced vector \n        \"\"\"\n        #coherence_distance = ra\n        centerU= 0\n        centerV= 0\n        num_neighbors = 0\n        for agent in agents:\n            if not agent == self:\n                dist = self.position.DistanceTo(agent.position)\n                if dist<= radius:\n                    num_neighbors +=1\n                    centerU += agent.u\n                    centerV += agent.v\n\n        #get the average vector\n        if  num_neighbors > 0:\n            centerU /= num_neighbors\n            centerV /= num_neighbors\n\n            #unitize the product vector of the coherence  \n            cohesion_unit_vect = rg.Vector2d(centerU-self.u, centerV-self.v)\n            cohesion_unit_vect = self.UnitizeEffect(u_div, v_div,cohesion_unit_vect) * coh_fac\n\n            return cohesion_unit_vect\n\n        else:\n            return rg.Vector2d(0,0)\n\n    # fx for Alignment (match velocity)\n    def Alignment(self, radius, agents, u_div, v_div, align_fac):\n        \n        \"\"\"within the specified radius we need to iterate over each agent apart from ours and do the following:\n        -> calculate the average velocity [adding all the velocities and dividing the result with the total number of neighbors]\n        \"\"\"\n        #radius = 10\n\n        average_du = 0\n        average_dv = 0\n        num_neighbors = 0\n\n        for agent in agents:\n            if not agent == self:\n                dist = self.position.DistanceTo(agent.position)\n                if dist <= radius:\n                    num_neighbors +=1\n                    average_du += agent.du\n                    average_dv += agent.dv\n        \n        if  num_neighbors > 0:\n            average_du /= num_neighbors\n            average_dv /= num_neighbors\n\n            align_unit_vect = rg.Vector2d(average_du, average_dv)\n            align_unit_vect = self.UnitizeEffect(u_div, v_div,align_unit_vect) * align_fac\n\n            return align_unit_vect\n\n        else:\n            return rg.Vector2d(0,0)\n    \n    #pending: trial\n    def Separation (self, radius, agents, u_div, v_div, avoid_fac):\n        # fx for Separation\n        \"\"\"within the specified radius we need to iterate over each agent apart from ours and do the following:\n        -> define how close two agents can be [min distance before collision]\n        -> define a new direction [maybe reversed]\n        \"\"\"\n        move_dU= 0\n        move_dV= 0\n\n        min_dist = 1000000\n        closest_agent = self\n\n        for agent in agents:\n            if not agent == self:\n                dist = self.position.DistanceTo(agent.position)\n                if dist<= radius:\n                    if dist < min_dist:\n                        min_dist = dist\n                        closest_agent = agent\n        if closest_agent != self:\n            move_dU += self.u - closest_agent.u\n            move_dV += self.v - closest_agent.v\n\n            avoid_unit_vect = rg.Vector2d(move_dU, move_dV)\n            avoid_unit_vect = self.UnitizeEffect(u_div, v_div,avoid_unit_vect) * avoid_fac\n            return avoid_unit_vect\n\n        else:\n            return rg.Vector2d(0,0)\n    \n\n    #checks the boundaries and for end of life of agent\n    def withinBounds (self): \n        \"\"\"\n        ->check if (0<=u,v<=1)\n        ->if not mirror u (*-1)\n        ->\n        \"\"\"\n        if abs(0.5 - self.u) >= 0.5 :       \n            if self.u < 0:\n                self.u = 0\n\n            elif self.u > 1:\n                self.u = 1\n            self.du*=-1\n            #self.right_force *=-1\n            #self.arrived=True\n            \n        #we check if it has arrived (finished)  \n        if self.v >= 1:\n            self.v = 1\n            self.arrived = True\n\n    #update the distance to goal until reaching the radius and then change direction and disable the agent \n    def UpdateSubAgentProgress(self, radius,factor, u_div, v_div):\n        #calculate distance to the goal point at certain instant\n        raw_du = self.sub_goal_u - self.u\n        raw_dv = self.sub_goal_v - self.v\n        vector = rg.Vector2d(raw_du, raw_dv)\n        distance = vector.Length\n\n        #update the direction unit towards the goal\n        unitized_vector = self.UnitizeEffect(u_div, v_div, vector)\n        self.right_force = unitized_vector.X * factor\n        self.up_force = unitized_vector.Y * factor\n\n        #if the goal was reached, flip the du and right_force (the latter will be contant till the end of the game)\n        if distance <= radius:\n            self.du *= -1  \n            #disable subagent  \n            self.isSubAgent = False \n            self.right_force *= -1    \n            \n\n        \n\n\n    \n    # pending: fx for limiting speed?\n\n    # helper fxs:7\n\n    # add the effect to the new veloctity vector of the agent that will be added later to its current velocity\n    # as an input is the vector of a certain effect, the function does the following\n    # --> unitize the vector\n    # --> multiply by the effect value \n    # --> add this value to sum of new velocity vector \n    # --> this fx is called in each effect fx \n    def UnitizeEffect(self, u_div, v_div, vector_2b_unitised):           \n        vector_2b_unitised.Unitize()\n        vector_2b_unitised = rg.Vector2d(vector_2b_unitised.X/u_div, vector_2b_unitised.Y/v_div)\n        return vector_2b_unitised\n\n    # adds the new velocty vector to the current velocity vector and unitizes it \n    def AddTotalEffect(self, u_div, v_div, effects_vector):\n        effects_vector += rg.Vector2d(self.du, self.dv)\n        return self.UnitizeEffect(u_div, v_div, effects_vector)\n\n    # update the agent's params and move it one step forward while checking its elgibility for movement\n    def AgentStep(self, effects_vector):\n\n        self.du = effects_vector.X\n        self.dv = effects_vector.Y\n        \n        if self.dv< 0:\n            self.dv *=-10\n        self.u += self.du\n        self.v += self.dv\n        #checks the agent compliance with boundary\n        self.withinBounds()\n\n        self.pts.append(self.surface.PointAt(self.u, self.v))\n\nclass SubGoal(object):\n\n    def __init__(self):\n        self.u = 0\n        self.v = 0\n        self.buffer_Zone = 0\n         \n\n    #hello Eleniiiii\n    #hello Ahmed\n######################################################################################################################################\n# the execution function:\n# given the list of different points to initiate the agents do:\n# a for loop iterating over the lists, instantiating each agent in the list then instantaiting an environment given all these agents\n# afterwards, for each environment do some action till a certain time t\n# afterwards instantiate a bigger environment containing all agents and giving it a certain value for all parameters.\n#helpful functions:\ndef Remap(value, min, max, new_min, new_max):\n    old_range = max - min\n    new_range = new_max - new_min\n    return (((value - min)* new_range)/ old_range) + new_min\n\n\n#Swap UV directions of surface if needed\ncorner_b= surface.PointAt(1,0)\ncorner_d= surface.PointAt(0,1)\n\nif corner_b.Z > corner_d.Z:\n    surface.Transpose(True)\n\nall_agents = []\n################################strt with first phase (t1)###############################\ninitial_env_list = []\nu_lists = th.tree_to_list(u_lists)\ntarget_factors = th.tree_to_list(target_factors)\nfor u_list, t_factor in zip(u_lists, target_factors):\n    #instantiate an instance of the environment:\n    new_env = Environment(u_div, v_div, surface)\n    new_env.populate_agents(u_list, t_factor)\n    #add all agents to the big list\n    all_agents.extend(new_env.agents)\n    initial_env_list.append(new_env)\n\npts_list = []\n#depending on the input timestep we update the agents\nfor t in range(time_1):\n    for env in initial_env_list:\n        env.update_agents_pos(coherence_rad, coherence_fac, align_rad, align_fac, avoid_rad, avoid_fac, Coherence_T, Alignment_T, Separation_T)\n\n###############################second phase (t2)#########################################\n#Create a new env containing all agents\ncombined_env = Environment(u_div, v_div, surface, all_agents)\n#add the new sub_agents\n\ngoals, sub_agents = combined_env.populate_sub_agents(initial_env_list, num_new_agents, shift_up_factor, shift_down_factor, sub_goal_fac)\n\nfor t in range(time_2):\n    combined_env.update_agents_pos(coherence_rad2, coherence_fac2, align_rad2, align_fac2, avoid_rad2, avoid_fac2, Coherence_T2, Alignment_T2, Separation_T2, sub_goal_rad, sub_goal_fac)\n\nlist_pts = []\nmain_paths=[]\nsec_paths = []\nmain_agents = deepcopy(combined_env.all_agents)\nfor agent in main_agents:\n    if agent.right_force != 0:\n        path = surface.InterpolatedCurveOnSurface(agent.pts,tolerance) \n        if Rebuild_T:\n            path= path.Rebuild(rebuild_points, rebuild_degree, True)\n        main_paths.append(path)  \n    else:\n        path = surface.InterpolatedCurveOnSurface(agent.pts,tolerance) \n        if Rebuild_T:\n            path= path.Rebuild(rebuild_points, rebuild_degree, True)\n        sec_paths.append(path)\n\n#sub_agents = th.list_to_tree(sub_agents)\nmain_paths = th.list_to_tree(main_paths)\nsec_paths = th.list_to_tree(sec_paths)\nlist_pts = th.list_to_tree(list_pts)\n",
  "language": "python",
  "imports": [
    "Rhino",
    "Rhino.Geometry",
    "ghpythonlib"
  ],
  "has_docstring": false
}