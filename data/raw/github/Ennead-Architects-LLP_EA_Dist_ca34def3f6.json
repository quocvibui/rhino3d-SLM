{
  "source_url": "https://github.com/Ennead-Architects-LLP/EA_Dist/blob/635520d89b8308b78eabf5b60bb80121d0fa3838/Apps/lib/EnneadTab/ENVIRONMENT.py",
  "repo": "Ennead-Architects-LLP/EA_Dist",
  "repo_stars": 0,
  "repo_description": null,
  "license": "unknown",
  "filepath": "Apps/lib/EnneadTab/ENVIRONMENT.py",
  "instruction": "Environment configuration and detection module for EnneadTab.\r\n\r\nThis module handles environment setup, path configurations, and runtime environment detection\r\nfor the EnneadTab ecosystem. It...",
  "code": "#!/usr/bin/python\r\n# -*- coding: utf-8 -*-\r\n\"\"\"Environment configuration and detection module for EnneadTab.\r\n\r\nThis module handles environment setup, path configurations, and runtime environment detection\r\nfor the EnneadTab ecosystem. It supports multiple applications including Revit, Rhino,\r\nand terminal environments.\r\n\r\nKey Features:\r\n- Path configuration for development and production environments\r\n- Application environment detection (Revit, Rhino, Grasshopper)\r\n- System environment checks (AVD, Python version)\r\n- Filesystem management for temp and dump folders\r\n- Network drive availability monitoring\r\n\r\nNote:\r\n    Network drive connectivity is managed through GitHub distribution rather than \r\n    direct network mapping to optimize IT infrastructure costs.\r\n\r\n\r\n\r\nUnfortunately IT department cannot make L drive and other drive to be connnected by default ever since the Azure dirve migration.\r\nThere are money to be saved to disconnect the drive, so we need to use github to push update to all users.\r\n\r\nDont tell me it is a security risk, it is NOT.\r\n\r\n\r\n\r\n\"\"\"\r\n\r\nimport os\r\nimport sys\r\nfrom datetime import datetime\r\nimport json\r\nimport getpass\r\n\r\ncurrent_user_name = getpass.getuser()\r\n\r\n\r\nPLUGIN_NAME = \"EnneadTab\"\r\nPLUGIN_ABBR = \"EA\"\r\nPLUGIN_EXTENSION = \".sexyDuck\"\r\n\r\nIS_PY3 = sys.version.startswith(\"3\")\r\nIS_PY2 = not IS_PY3\r\nIS_IRONPYTHON = sys.platform == \"cli\"\r\n\r\n\r\n# this is the repo folder if you are a developer, or EA_dist if you are a normal user\r\nROOT = os.path.dirname(\r\n    os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))\r\n)\r\n\r\nUSER_PROFILE_FOLDER = os.environ[\"USERPROFILE\"]\r\nUSER_DOCUMENT_FOLDER = os.path.join(USER_PROFILE_FOLDER, \"Documents\")\r\nUSER_DOWNLOAD_FOLDER = os.path.join(USER_PROFILE_FOLDER, \"downloads\")\r\n\r\nUSER_DESKTOP_FOLDER = os.path.join(USER_PROFILE_FOLDER, \"Desktop\")\r\nONE_DRIVE_DESKTOP_FOLDER = os.path.join(USER_PROFILE_FOLDER, \r\n                                        \"OneDrive - Ennead Architects\", \"Desktop\")\r\n\r\nif not os.path.exists(ONE_DRIVE_DESKTOP_FOLDER):\r\n    ONE_DRIVE_DESKTOP_FOLDER = USER_DESKTOP_FOLDER\r\nUSER_APPDATA_FOLDER = os.path.join(USER_PROFILE_FOLDER, \"AppData\")\r\nECO_SYS_FOLDER = os.path.join(USER_DOCUMENT_FOLDER, \r\n                            \"{} Ecosystem\".format(PLUGIN_NAME))\r\nDUMP_FOLDER = os.path.join(ECO_SYS_FOLDER, \"Dump\")\r\nINSTALLATION_FOLDER = os.path.join(ROOT, \"Installation\")\r\n\r\ndef _secure_folder(folder):\r\n    if not os.path.exists(folder):\r\n        try:\r\n            os.makedirs(folder)\r\n        except Exception as e:\r\n            print(\"Cannot secure folder [{}] becasue {}\".format(folder, e))\r\n\r\ndef _secure_folder_safe(folder):\r\n    \"\"\"Safely create folder with better error handling for network drives\"\"\"\r\n    if not os.path.exists(folder):\r\n        try:\r\n            os.makedirs(folder)\r\n        except Exception as e:\r\n            # Don't print error for network drives that might not be available\r\n            if not folder.startswith(\"L:\\\\\"):\r\n                print(\"Cannot secure folder [{}] becasue {}\".format(folder, e))\r\n\r\ndef _execute_map_compatible(func, iterable, *args):\r\n    \"\"\"Execute a function on each item in an iterable, compatible with both IronPython 2.7 and Python 3.\r\n    \r\n    Args:\r\n        func: Function to execute\r\n        iterable: Iterable of items to process\r\n        *args: Additional arguments to pass to func\r\n    \r\n    Returns:\r\n        List of results (for compatibility)\r\n    \"\"\"\r\n    results = []\r\n    for item in iterable:\r\n        if args:\r\n            result = func(item, *args)\r\n        else:\r\n            result = func(item)\r\n        results.append(result)\r\n    return results\r\n\r\n# Fix: Use compatible approach for both IronPython 2.7 and Python 3\r\n_execute_map_compatible(_secure_folder, [ECO_SYS_FOLDER, DUMP_FOLDER])\r\n\r\n\r\n\r\n\r\nAPP_FOLDER = os.path.join(ROOT, \"Apps\")\r\n\r\n\r\nLIB_FOLDER = os.path.join(APP_FOLDER, \"lib\")\r\nCORE_FOLDER = os.path.join(LIB_FOLDER, PLUGIN_NAME)\r\nIMAGE_FOLDER = os.path.join(CORE_FOLDER, \"images\")\r\nAUDIO_FOLDER = os.path.join(CORE_FOLDER, \"audios\")\r\nDOCUMENT_FOLDER = os.path.join(CORE_FOLDER, \"documents\")\r\nSCRIPT_FOLDER = os.path.join(CORE_FOLDER, \"scripts\")\r\n\r\n\r\nEXE_PRODUCT_FOLDER = os.path.join(LIB_FOLDER, \"ExeProducts\")\r\nWINDOW_TEMP_FOLDER = os.path.join(\"C:\\\\\", \"temp\", \"{}_Dump\".format(PLUGIN_NAME))\r\n_secure_folder(WINDOW_TEMP_FOLDER)\r\n\r\nDEPENDENCY_FOLDER = os.path.join(LIB_FOLDER, \"dependency\")\r\nif IS_PY2:\r\n    DEPENDENCY_FOLDER = os.path.join(DEPENDENCY_FOLDER, \"py2\")\r\nelse:\r\n    DEPENDENCY_FOLDER = os.path.join(DEPENDENCY_FOLDER, \"py3\")\r\nPY3_DEPENDENCY_FOLDER = os.path.join(LIB_FOLDER, \"dependency\", \"py3\")\r\n\r\n\r\n\r\n\r\nREVIT_FOLDER_KEYNAME = \"_revit\"\r\nREVIT_FOLDER = os.path.join(APP_FOLDER, REVIT_FOLDER_KEYNAME)\r\n\r\n################# rhino extension ####################\r\nRHINO_FOLDER_KEYNAME = \"_rhino\"\r\nRHINO_FOLDER = os.path.join(APP_FOLDER, RHINO_FOLDER_KEYNAME)\r\nDIST_RUI_CLASSIC = os.path.join(RHINO_FOLDER, \"{}_For_Rhino_Classic.rui\".format(PLUGIN_NAME))\r\nDIST_RUI_MODERN = os.path.join(RHINO_FOLDER, \"{}_For_Rhino_Modern.rui\".format(PLUGIN_NAME))\r\nACTIVE_MODERN_RUI = os.path.join(DUMP_FOLDER, \"{}_For_Rhino_Modern.rui\".format(PLUGIN_NAME))\r\nINSTALLATION_RUI = os.path.join(INSTALLATION_FOLDER, \"{}_For_Rhino_Installer.rui\".format(PLUGIN_NAME))\r\nRHINO_INSTALLER_SETUP_FOLDER = os.path.join(LIB_FOLDER, PLUGIN_NAME, \"RHINO\")\r\n\r\n################# indesign extension ####################\r\nINDESIGN_FOLDER_KEYNAME = \"_indesign\"\r\nINDESIGN_FOLDER = os.path.join(APP_FOLDER, INDESIGN_FOLDER_KEYNAME)\r\n\r\n################### knowledge database ####################\r\nKNOWLEDGE_RHINO_FILE = \"{}\\\\knowledge_rhino_database{}\".format(RHINO_FOLDER, PLUGIN_EXTENSION)\r\nKNOWLEDGE_REVIT_FILE = \"{}\\\\knowledge_revit_database{}\".format(REVIT_FOLDER, PLUGIN_EXTENSION)\r\nfor _ in [KNOWLEDGE_RHINO_FILE, KNOWLEDGE_REVIT_FILE]:\r\n    if not os.path.exists(_):\r\n        import json\r\n        try:\r\n            with open(_, \"w\") as f:\r\n                json.dump({}, f, indent=4)\r\n        except Exception as e:\r\n            print(\"Cannot create file [{}] becasue {}\".format(_, e))\r\n\r\n################### revit extension ####################\r\nPRIMARY_EXTENSION_NAME = \"EnneaDuck\"\r\nREVIT_PRIMARY_EXTENSION = os.path.join(\r\n    REVIT_FOLDER, \"{}.extension\".format(PRIMARY_EXTENSION_NAME)\r\n)\r\nREVIT_PRIMARY_TAB = os.path.join(REVIT_PRIMARY_EXTENSION, \"{}.tab\".format(PLUGIN_NAME))\r\nREVIT_LIBRARY_TAB = os.path.join(REVIT_PRIMARY_EXTENSION, \"{} Library.tab\".format(PLUGIN_NAME))\r\nREVIT_TAILOR_TAB = os.path.join(REVIT_PRIMARY_EXTENSION, \"{} Tailor.tab\".format(PLUGIN_NAME))\r\n\r\n\r\n\r\n#################### L drive folder ####################\r\n\r\n\r\nif datetime.now() >= datetime(2025, 7, 15) or current_user_name == \"szhang\":\r\n    L_DRIVE_HOST_FOLDER = os.path.join(\"L:\\\\\", \"4b_Design Technology\")\r\n    DB_FOLDER = os.path.join(L_DRIVE_HOST_FOLDER, \"05_EnneadTab-DB\")\r\nelse:\r\n    L_DRIVE_HOST_FOLDER = os.path.join(\"L:\\\\\", \"4b_Applied Computing\")\r\n    DB_FOLDER = os.path.join(L_DRIVE_HOST_FOLDER, \"EnneadTab-DB\")\r\n\r\nSHARED_DUMP_FOLDER = os.path.join(DB_FOLDER, \"Shared Data Dump\")\r\n\r\n# Public temp folder for shared temporary files\r\nPUBLIC_TEMP_FOLDER = os.path.join(DB_FOLDER, \"temp\")\r\n\r\nSTAND_ALONE_FOLDER = os.path.join(DB_FOLDER, \"Stand Alone Tools\")\r\n\r\n# Backup repository in case SH cannot use L drive\r\nBACKUP_REPO_FOLDER = os.path.join(DB_FOLDER, \"BackupRepo\")\r\n\r\n\r\n############# engine ####################\r\nENGINE_FOLDER = os.path.join(APP_FOLDER, \"_engine\")\r\nSITE_PACKAGES_FOLDER = os.path.join(ENGINE_FOLDER, \"Lib\")\r\n# Fix: Use compatible approach for both IronPython 2.7 and Python 3\r\n_execute_map_compatible(_secure_folder, [ECO_SYS_FOLDER, DUMP_FOLDER])\r\n\r\n# Use safer folder creation for network drives\r\n_execute_map_compatible(_secure_folder_safe, [L_DRIVE_HOST_FOLDER, DB_FOLDER, SHARED_DUMP_FOLDER,\r\n                     PUBLIC_TEMP_FOLDER, STAND_ALONE_FOLDER, BACKUP_REPO_FOLDER,\r\n                     ENGINE_FOLDER, SITE_PACKAGES_FOLDER])\r\n\r\nIS_OFFLINE_MODE = not os.path.exists(SHARED_DUMP_FOLDER)\r\nif IS_OFFLINE_MODE:\r\n    SHARED_DUMP_FOLDER = DUMP_FOLDER\r\n\r\n\r\nERROR_LOG_GOOGLE_FORM_SUBMIT = \"https://docs.google.com/forms/d/e/1FAIpQLScLvUOwyY84oqCVhoLie2KzLIyYkTBt3fxengOhmhIXaVzhdA/formResponse\"\r\nERROR_LOG_GOOGLE_FORM_RESULT = \"https://docs.google.com/forms/d/1nEbgC-Nbaiwrr5FFVfVgqc_hUqzBrtvus8aHY6aL4lE/edit?pli=1#responses\"\r\n\r\n\r\nUSAGE_LOG_GOOGLE_FORM_SUBMIT = \"https://docs.google.com/forms/d/e/1FAIpQLSc2Ruskj8BQYYA91vOaXqg_mOk0l67ca_ZGXpS-e-LwfU9bVA/formResponse\"\r\nUSAGE_LOG_GOOGLE_FORM_RESULT = \"https://docs.google.com/forms/d/12Ew3_3Mmrl4P-grEnVkK8cIuLQzDAEm0ECqBmJI_7oA/edit#responses\"\r\n\r\n####################################\r\n\r\n\r\n# Global cache for deletion counter to reduce file I/O\r\n_DELETION_COUNTER_CACHE = None\r\n\r\ndef _delete_folder_or_file_after_date(path, date_YYMMDD_tuple, max_delete_per_day = 200):\r\n    \"\"\"Delete a folder if current date is past the specified date.\r\n    \r\n    Args:\r\n        path (str): Path to the folder or file to be deleted\r\n        date_YYMMDD_tuple (tuple): Date tuple in format (year, month, day)\r\n        max_delete_per_day (int): Maximum number of deletions allowed per day (default: 200)\r\n    \"\"\"\r\n    global _DELETION_COUNTER_CACHE\r\n    \r\n    if not os.path.exists(path):\r\n        return\r\n        \r\n    delete_after = datetime(*date_YYMMDD_tuple)\r\n    if datetime.now() >= delete_after:\r\n        # Check daily deletion limit\r\n        import time\r\n        import json\r\n        \r\n        deletion_counter_file = os.path.join(DUMP_FOLDER, \"daily_deletion_counter.DuckLock\")\r\n        current_date = datetime.now().strftime(\"%Y-%m-%d\")\r\n        \r\n        # Use cache or load from file\r\n        if _DELETION_COUNTER_CACHE is None or _DELETION_COUNTER_CACHE.get(\"date\") != current_date:\r\n            deletion_data = {\"date\": current_date, \"count\": 0}\r\n            if os.path.exists(deletion_counter_file):\r\n                try:\r\n                    with open(deletion_counter_file, \"r\") as f:\r\n                        deletion_data = json.load(f)\r\n                except:\r\n                    pass\r\n            \r\n            # Reset counter if it's a new day\r\n            if deletion_data.get(\"date\") != current_date:\r\n                deletion_data = {\"date\": current_date, \"count\": 0}\r\n            \r\n            _DELETION_COUNTER_CACHE = deletion_data\r\n        else:\r\n            deletion_data = _DELETION_COUNTER_CACHE\r\n        \r\n        # Check if we've reached the daily limit\r\n        if deletion_data[\"count\"] >= max_delete_per_day:\r\n            return\r\n        \r\n        # Perform deletion\r\n        import shutil\r\n        try:\r\n            if os.path.isdir(path):\r\n                shutil.rmtree(path)\r\n            else:\r\n                os.remove(path)\r\n            \r\n            # Increment deletion counter\r\n            deletion_data[\"count\"] += 1\r\n            _DELETION_COUNTER_CACHE = deletion_data\r\n            \r\n            # Only save to file when reaching the max delete count\r\n            if deletion_data[\"count\"] >= max_delete_per_day:\r\n                try:\r\n                    with open(deletion_counter_file, \"w\") as f:\r\n                        json.dump(deletion_data, f)\r\n                except:\r\n                    pass\r\n                \r\n        except Exception as e:\r\n            pass\r\n\r\n\r\n\r\n# this is to remove any transitional folder from IT transition, not intented to be ussed anywhere else\r\n__legacy_one_drive_folders = [os.path.join(USER_PROFILE_FOLDER, \"OneDrive - Ennead Architects\", \"Documents\", \"{} Ecosystem\".format(PLUGIN_NAME)),\r\n                            os.path.join(USER_PROFILE_FOLDER, \"OneDrive - Ennead Architects\", \"Documents\", \"{}-Ecosystem\".format(PLUGIN_NAME))]\r\n\r\n# no longer plan to have both folder, so delete the modern one and keep using the old one. i have resolved this by rerouting rvb file for rhino.\r\ndepreciated_ECO_SYS_FOLDER_MODERN = os.path.join(USER_DOCUMENT_FOLDER, \r\n                                     \"{}-Ecosystem\".format(PLUGIN_NAME))\r\n\r\ndepreciated_dist_lite_folder = os.path.join(ECO_SYS_FOLDER, \"EA_Dist_Lite\")\r\ndepreciated_enneadPLUS_menu = os.path.join(RHINO_FOLDER, \"Ennead+.menu\")\r\n\r\n\r\ndepreciated_log = os.path.join(os.path.expanduser(\"~\"), \"Desktop\", \"I just blue myself.log\")\r\n\r\n# Fix: Use compatible approach for both IronPython 2.7 and Python 3\r\n# _execute_map_compatible(_delete_folder_or_file_after_date, __legacy_one_drive_folders, (2025, 2, 1))\r\n\r\n_delete_folder_or_file_after_date(depreciated_enneadPLUS_menu, (2025, 4, 1))\r\n_delete_folder_or_file_after_date(depreciated_dist_lite_folder, (2025, 5, 1))\r\n_delete_folder_or_file_after_date(depreciated_ECO_SYS_FOLDER_MODERN, (2025, 5, 1))\r\n\r\n_delete_folder_or_file_after_date(depreciated_log, (2025, 5, 1))\r\n\r\n####################################\r\ndef cleanup_dump_folder():\r\n    \"\"\"Clean up temporary files from the dump folder.\r\n\r\n    Removes files older than 3 days from the DUMP_FOLDER, excluding protected file types:\r\n    .json, PLUGIN_EXTENSION, .txt, .DuckLock, and .rui files.\r\n    \r\n    This function runs silently and handles file deletion errors gracefully.\r\n    \"\"\"\r\n    import os\r\n    import time\r\n\r\n    cutoff_time = time.time() - (3 * 24 * 60 * 60)  # 3 days\r\n    protected_extensions = {'.json', PLUGIN_EXTENSION, \".txt\", \".lock\", \".DuckLock\", \".rui\"}\r\n\r\n    for filename in os.listdir(DUMP_FOLDER):\r\n        file_path = os.path.join(DUMP_FOLDER, filename)\r\n        if not os.path.isfile(file_path):\r\n            continue\r\n            \r\n        file_ext = os.path.splitext(filename)[1].lower()\r\n\r\n        if file_ext in protected_extensions:\r\n            continue\r\n            \r\n        if os.path.getmtime(file_path) < cutoff_time:\r\n            try:\r\n                os.remove(file_path)\r\n            except:\r\n                pass\r\n\r\n\r\ndef should_check_l_drive():\r\n    \"\"\"Determine if L drive should be checked based on time elapsed since last check.\r\n    \r\n    Ensures check happens at most once per hour.\r\n    \r\n    Returns:\r\n        bool: True if an hour has passed since last check, False otherwise.\r\n    \"\"\"\r\n    import time\r\n    import os.path\r\n    \r\n    timestamp_file = os.path.join(DUMP_FOLDER, \"l_drive_check.DuckLock\")\r\n    current_time = time.time()\r\n    cutoff_time = current_time - (60 * 60)  # 1 hour\r\n    \r\n    # If lock file exists and is less than an hour old, don't check\r\n    if os.path.exists(timestamp_file):\r\n        if os.path.getmtime(timestamp_file) > cutoff_time:\r\n            return False\r\n    \r\n    # Update timestamp by touching the file\r\n    try:\r\n        with open(timestamp_file, \"w\") as f:\r\n            f.write(\"\")\r\n    except:\r\n        pass\r\n        \r\n    return True\r\n\r\ndef should_cleanup_dump_folder():\r\n    \"\"\"Determine if dump folder should be cleaned up based on time elapsed since last cleanup.\r\n    \r\n    Ensures cleanup happens at most once per day.\r\n    \r\n    Returns:\r\n        bool: True if a day has passed since last cleanup, False otherwise.\r\n    \"\"\"\r\n    import time\r\n    import os.path\r\n    \r\n    timestamp_file = os.path.join(DUMP_FOLDER, \"dump_cleanup.DuckLock\")\r\n    current_time = time.time()\r\n    cutoff_time = current_time - (24 * 60 * 60)  # 24 hours\r\n    \r\n    # If lock file exists and is less than a day old, don't cleanup\r\n    if os.path.exists(timestamp_file):\r\n        if os.path.getmtime(timestamp_file) > cutoff_time:\r\n            return False\r\n    \r\n    # Update timestamp by touching the file\r\n    try:\r\n        with open(timestamp_file, \"w\") as f:\r\n            f.write(\"\")\r\n    except:\r\n        pass\r\n        \r\n    return True\r\n\r\ndef is_avd():\r\n    \"\"\"Detect if running in Azure Virtual Desktop environment.\r\n\r\n    Returns:\r\n        bool: True if running in AVD or GPU-PD environment, False otherwise\r\n    \"\"\"\r\n    computer_name = get_computer_name()\r\n  \r\n    return \"avd\" in computer_name.lower() or \"gpupd\" in computer_name.lower()\r\n\r\ndef get_computer_name():\r\n    \"\"\"Get the computer name.\r\n\r\n    Returns:\r\n        str: Computer name\r\n\r\n    \"\"\"\r\n    try:\r\n        import clr  # pyright:ignore\r\n        from System.Net import Dns  # pyright:ignore\r\n\r\n        computer_name = Dns.GetHostName()\r\n    except:\r\n        try:\r\n            import socket\r\n            computer_name = socket.gethostname()\r\n        except:\r\n            # Final fallback for environments without socket module (embedded Python, etc.)\r\n            import os\r\n            computer_name = os.environ.get('COMPUTERNAME', os.environ.get('HOSTNAME', 'unknown'))\r\n\r\n    return computer_name\r\n\r\n\r\ndef is_Rhino_8():\r\n    \"\"\"Check if current environment is Rhino 8.\r\n\r\n    Returns:\r\n        bool: True if running in Rhino 8, False otherwise\r\n    \"\"\"\r\n\r\n    return str(get_rhino_version()) == \"8\"\r\n\r\ndef is_Rhino_7():\r\n    \"\"\"Check if current environment is Rhino 7.\r\n\r\n    Returns:\r\n        bool: True if running in Rhino 7, False otherwise\r\n    \"\"\"\r\n\r\n    return str(get_rhino_version()) == \"7\"\r\n\r\ndef get_rhino_version(main_version_only=True):\r\n    \"\"\"Retrieve the current Rhino version.\r\n\r\n    Args:\r\n        main_version_only (bool, optional): If True, returns only the major version number.\r\n            Defaults to True.\r\n\r\n    Returns:\r\n        str or None: Rhino version number if in Rhino environment, None otherwise\r\n    \"\"\"\r\n    if not IS_RHINO_ENVIRONMENT:\r\n        return None\r\n    import Rhino  # pyright: ignore\r\n\r\n    return Rhino.RhinoApp.ExeVersion  if main_version_only else Rhino.RhinoApp.Version\r\n\r\ndef is_Rhino_environment():\r\n    \"\"\"Check if the current environment is Rhino.\r\n\r\n    Returns:\r\n        bool: True if running in Rhino environment, False otherwise\r\n    \"\"\"\r\n    try:\r\n        import rhinoscriptsyntax  # pyright: ignore\r\n\r\n        return True\r\n    except:\r\n        return False\r\n\r\n\r\ndef is_Grasshopper_environment():\r\n    \"\"\"Check if current environment is Grasshopper.\r\n\r\n    Returns:\r\n        bool: True if running in Grasshopper environment, False otherwise\r\n    \"\"\"\r\n    try:\r\n        import Grasshopper  # pyright: ignore\r\n\r\n        return True\r\n    except:\r\n        return False\r\n\r\n\r\ndef is_Revit_environment():\r\n    \"\"\"Check if the current environment is Revit.\r\n\r\n    Returns:\r\n        bool: True if current environment is Revit.\r\n    \"\"\"\r\n    try:\r\n        from Autodesk.Revit import DB  # pyright: ignore\r\n\r\n        return True\r\n    except:\r\n        return False\r\n\r\n\r\ndef is_RhinoInsideRevit_environment():\r\n    \"\"\"Check if the current environment is RhinoInsideRevit.\r\n\r\n    Returns:\r\n        bool: True if current environment is RhinoInsideRevit\r\n    \"\"\"\r\n    try:\r\n        import clr  # pyright: ignore\r\n\r\n        clr.AddReference(\"RhinoCommon\")\r\n        clr.AddReference(\"RhinoInside.Revit\")\r\n        return True\r\n    except:\r\n        return False\r\n\r\n\r\ndef is_terminal_environment():\r\n    \"\"\"Check if the current environment is within the terminal.\r\n\r\n    Returns:\r\n        bool: True if current environment is a terminal.\r\n    \"\"\"\r\n    return not is_Rhino_environment() and not is_Revit_environment()\r\n\r\n\r\ndef unit_test():\r\n    import inspect\r\n    # get all the global varibales in the current script\r\n\r\n    for i, var_name in enumerate(sorted(globals())):\r\n        var_value = globals()[var_name]\r\n\r\n        if inspect.ismodule(var_value):\r\n            continue\r\n\r\n        if not var_name.startswith(\"_\") and not callable(var_value):\r\n            print(var_name, \" = \", var_value)\r\n\r\n            if isinstance(var_value, bool):\r\n                continue\r\n\r\n            if not isinstance(var_value, list):\r\n                var_value = [var_value]\r\n\r\n            for item in var_value:\r\n                if \"\\\\\" in item:\r\n                    is_ok = os.path.exists(item) or os.path.isdir(item)\r\n\r\n                    # Check old paths that should be deleted\r\n                    if \"depreciated_\" in var_name:\r\n                        if is_ok:\r\n                            print(\"!!!!!!!!!!!!!!!!!!WARNING: depreciated folder still exists and should be deleted: {}\".format(item))\r\n                        continue\r\n                    else:\r\n                        # Check required paths that should exist\r\n                        if not is_ok:\r\n                            print(\"!!!!!!!!!!!!!!ERROR: Required path does not exist: {}\".format(item))\r\n                        # assert is_ok\r\n\r\n\r\nIS_AVD = is_avd()\r\nIS_RHINO_ENVIRONMENT = is_Rhino_environment()\r\nIS_RHINO_7 = is_Rhino_7()\r\nIS_RHINO_8 = is_Rhino_8()\r\nIS_GRASSHOPPER_ENVIRONMENT = is_Grasshopper_environment()\r\nIS_REVIT_ENVIRONMENT = is_Revit_environment()\r\nIS_RHINOINSIDEREVIT_ENVIRONMENT = is_RhinoInsideRevit_environment()\r\n\r\ndef get_app_name():\r\n    \"\"\"Determine the current application environment.\r\n\r\n    Returns:\r\n        str: Application identifier - 'revit', 'rhino', or 'terminal'.\r\n    \"\"\"\r\n    app_name = \"terminal\"\r\n    if IS_REVIT_ENVIRONMENT:\r\n        app_name = \"revit\"\r\n    elif IS_RHINO_ENVIRONMENT:\r\n        app_name = \"rhino\"\r\n    return app_name\r\n\r\ndef alert_l_drive_not_available(play_sound = False):\r\n    \"\"\"Check L drive availability and notify user if unavailable.\r\n\r\n    Args:\r\n        play_sound (bool): If True, plays an error sound when L drive is unavailable.\r\n\r\n    Returns:\r\n        bool: True if L drive is available, False otherwise.\r\n    \"\"\"\r\n    # record the success/failed rate of this check, date as key, value is a dict with success and failed count\r\n    # if in the last 60 days it has neever been sucefful then i can tell this computer will never connect to L drive so lets just make a mark file so there is not need to check anymore\r\n    # this recording should be done ins a sepeate process to allow non-blocking\r\n    # the mark file should be in the DUMP_FOLDER\r\n    # the mark file should be named as l_drive_check.DuckLock\r\n\r\n\r\n\r\n    check_conclusion_file = os.path.join(DUMP_FOLDER, \"l_drive_check_conclusion.SmartDuck\")\r\n    if os.path.exists(check_conclusion_file):\r\n        return False\r\n    \r\n\r\n    check_results_file = os.path.join(DUMP_FOLDER, \"l_drive_check.DuckLock\")\r\n    if os.path.exists(check_results_file):\r\n        try:\r\n            with open(check_results_file, \"r\") as f:\r\n                content = f.read().strip()\r\n                if content:\r\n                    check_results = json.loads(content)\r\n                else:\r\n                    check_results = {}\r\n        except (json.JSONDecodeError, ValueError):\r\n            check_results = {}\r\n    else:\r\n        check_results = {}\r\n    \r\n    \r\n    def record_check_result(success):\r\n        import time\r\n        timestamp = datetime.now().strftime(\"%Y-%m-%d\")\r\n        if timestamp not in check_results:\r\n            check_results[timestamp] = {\"success\": 0, \"failed\": 0}\r\n        \r\n        # Fix: Use string keys instead of boolean values\r\n        if success:\r\n            check_results[timestamp][\"success\"] += 1\r\n        else:\r\n            check_results[timestamp][\"failed\"] += 1\r\n            \r\n        with open(check_results_file, \"w\") as f:\r\n            json.dump(check_results, f, indent=4)\r\n        \r\n        # Check if file is older than 60 days and has never been successful\r\n        current_time = time.time()\r\n        sixty_days_ago = current_time - (60 * 24 * 60 * 60)\r\n        \r\n        # Only check for conclusion if we have data spanning 60 days\r\n        if os.path.getmtime(check_results_file) < sixty_days_ago:\r\n            # Check if there have been NO successful connections in any recorded day\r\n            if all(check_results[date][\"success\"] == 0 for date in check_results):\r\n                with open(check_conclusion_file, \"w\") as f:\r\n                    f.write(\"This computer will never connect to L drive, maybe a laptop or from outside office organization.\")\r\n                return\r\n\r\n    if os.path.exists(L_DRIVE_HOST_FOLDER):\r\n        record_check_result(True)\r\n        return True\r\n    note = \"Friendly reminder! \\n\\nL drive is not available, please check your network connection or activate L drive manually.\\nEnneadTab will still work, just without some public asset, such as AI related features.\"\r\n    print(note)\r\n    if play_sound:\r\n        try:\r\n            import SOUND\r\n            SOUND.play_error_sound()\r\n        except:\r\n            pass        \r\n\r\n    record_check_result(False)\r\n    return False\r\n    \r\n        \r\n\r\n\r\n# Run maintenance operations\r\nif should_cleanup_dump_folder():\r\n    cleanup_dump_folder()\r\n\r\nif should_check_l_drive():\r\n    alert_l_drive_not_available()\r\n###############\r\nif __name__ == \"__main__\":\r\n    unit_test()\r\n\r\n",
  "language": "python",
  "imports": [
    "Rhino",
    "RhinoCommon",
    "rhinoscriptsyntax"
  ],
  "has_docstring": true
}