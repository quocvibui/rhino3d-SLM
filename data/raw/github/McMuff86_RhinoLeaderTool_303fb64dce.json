{
  "source_url": "https://github.com/McMuff86/RhinoLeaderTool/blob/880966d9ae5c50786ba91882e3ffffcddcc64e1d/import_leaders_from_excel.py",
  "repo": "McMuff86/RhinoLeaderTool",
  "repo_stars": 0,
  "repo_description": null,
  "license": "unknown",
  "filepath": "import_leaders_from_excel.py",
  "instruction": "Import leaders from excel",
  "code": "#! python 3\n# -*- coding: utf-8 -*-\nimport rhinoscriptsyntax as rs\nimport scriptcontext as sc\nimport Rhino\nimport os\n\n\ndef load_config():\n    try:\n        script_dir = os.path.dirname(__file__)\n    except Exception:\n        script_dir = os.getcwd()\n    local_cfg = os.path.join(script_dir, \"config.json\")\n    default = {\n        \"export\": {\"na_value\": \"NA\"}\n    }\n    try:\n        import json\n        cfg_to_use = local_cfg if os.path.isfile(local_cfg) else None\n        if cfg_to_use:\n            with open(cfg_to_use, \"r\", encoding=\"utf-8\") as f:\n                file_cfg = json.load(f)\n            for k, v in file_cfg.items():\n                default[k] = v\n    except Exception:\n        pass\n    return default\n\n\ndef get_na_value(cfg):\n    try:\n        return (cfg.get(\"export\", {}) or {}).get(\"na_value\", \"NA\")\n    except Exception:\n        return \"NA\"\n\n\ndef default_candidate_paths():\n    desktop = os.path.join(os.path.expanduser(\"~\"), \"Desktop\")\n    doc_path = sc.doc.Path or \"\"\n    base_dir = os.path.dirname(doc_path) if doc_path else desktop\n    doc_name = sc.doc.Name or \"leader\"\n    base_name = os.path.splitext(doc_name)[0] or \"leader\"\n    return [\n        os.path.join(base_dir, f\"{base_name}_leader_export.xlsx\"),\n        os.path.join(desktop, f\"{base_name}_leader_export.xlsx\"),\n        os.path.join(base_dir, f\"{base_name}_leader_texts.txt\"),\n    ]\n\n\ndef choose_input_file(prompt_always=True, allow_csv=False):\n    # Build filter\n    if allow_csv:\n        filter_str = \"Excel (*.xlsx)|*.xlsx||CSV (*.csv)|*.csv||All (*.*)|*.*||\"\n    else:\n        filter_str = \"Excel (*.xlsx)|*.xlsx||All (*.*)|*.*||\"\n\n    # Compute sensible defaults for dialog\n    desktop = os.path.join(os.path.expanduser(\"~\"), \"Desktop\")\n    doc_path = sc.doc.Path or \"\"\n    base_dir = os.path.dirname(doc_path) if doc_path else desktop\n    doc_name = sc.doc.Name or \"leader\"\n    base_name = os.path.splitext(doc_name)[0] or \"leader\"\n\n    if not prompt_always:\n        # Try candidates first\n        for p in default_candidate_paths():\n            if os.path.isfile(p):\n                return p\n\n    # Ask user via dialog\n    try:\n        # rs.OpenFileName(caption=None, filter=None, folder=None, filename=None, extension=None)\n        return rs.OpenFileName(\n            \"Select leader export file (XLSX)\",\n            filter_str,\n            base_dir,\n            f\"{base_name}_leader_export.xlsx\",\n            \"xlsx\",\n        )\n    except Exception:\n        return None\n\n\ndef read_xlsx(path):\n    try:\n        from openpyxl import load_workbook\n        wb = load_workbook(path, read_only=True, data_only=True)\n        try:\n            ws = wb.active\n            rows = list(ws.rows)\n            if not rows:\n                return [], []\n            header = [str(c.value) if c.value is not None else \"\" for c in rows[0]]\n            data = []\n            for r in rows[1:]:\n                data.append([c.value for c in r])\n            return header, data\n        finally:\n            try:\n                wb.close()\n            except Exception:\n                pass\n    except Exception as e:\n        # Fallback: parse .xlsx via zip (no external deps)\n        try:\n            modname = getattr(e, \"name\", \"\") if hasattr(e, \"name\") else \"\"\n        except Exception:\n            modname = \"\"\n        if isinstance(e, ImportError) or \"openpyxl\" in str(e) or modname == \"openpyxl\":\n            print(\"Using built-in XLSX reader (openpyxl not available).\")\n        else:\n            print(\"Using built-in XLSX reader (openpyxl error):\", e)\n        return read_xlsx_via_zip(path)\n\n\ndef read_xlsx_via_zip(path):\n    try:\n        import zipfile\n        import xml.etree.ElementTree as ET\n        with zipfile.ZipFile(path, 'r') as z:\n            # Shared strings\n            shared = []\n            try:\n                with z.open('xl/sharedStrings.xml') as f:\n                    ss = ET.parse(f).getroot()\n                    # ns handling\n                    for si in ss.findall('.//{*}si'):\n                        # concatenate all t children\n                        text_parts = []\n                        for t in si.findall('.//{*}t'):\n                            text_parts.append(t.text or '')\n                        shared.append(''.join(text_parts))\n            except KeyError:\n                shared = []\n\n            # First worksheet (xlsxwriter uses sheet1.xml)\n            with z.open('xl/worksheets/sheet1.xml') as f:\n                ws = ET.parse(f).getroot()\n\n            # Column letter to index\n            def col_to_idx(col):\n                idx = 0\n                for ch in col:\n                    if 'A' <= ch <= 'Z':\n                        idx = idx * 26 + (ord(ch) - ord('A') + 1)\n                return idx - 1  # zero-based\n\n            # Extract rows\n            rows = []\n            max_cols = 0\n            for row in ws.findall('.//{*}row'):\n                cells = {}\n                for c in row.findall('{*}c'):\n                    r = c.get('r') or ''  # e.g., 'B2'\n                    # split letters and digits\n                    letters = ''.join([ch for ch in r if ch.isalpha()])\n                    col_index = col_to_idx(letters) if letters else 0\n                    t = c.get('t')  # type\n                    v_elem = c.find('{*}v')\n                    is_elem = c.find('{*}is')\n                    val = ''\n                    if t == 's' and v_elem is not None:\n                        try:\n                            si = int(v_elem.text)\n                            val = shared[si] if 0 <= si < len(shared) else ''\n                        except Exception:\n                            val = ''\n                    elif t == 'inlineStr' and is_elem is not None:\n                        parts = []\n                        for tnode in is_elem.findall('.//{*}t'):\n                            parts.append(tnode.text or '')\n                        val = ''.join(parts)\n                    elif v_elem is not None and v_elem.text is not None:\n                        val = v_elem.text\n                    else:\n                        val = ''\n                    cells[col_index] = val\n                    if col_index + 1 > max_cols:\n                        max_cols = col_index + 1\n                # build ordered row\n                ordered = [cells.get(i, '') for i in range(max_cols)]\n                rows.append(ordered)\n\n            if not rows:\n                return [], []\n            header = [str(x) if x is not None else '' for x in rows[0]]\n            data = []\n            for r in rows[1:]:\n                data.append([x for x in r])\n            return header, data\n    except Exception as e:\n        print('XLSX zip-parse failed:', e)\n        return [], []\n\n\ndef read_csv_generic(path):\n    try:\n        import csv\n        with open(path, \"r\", encoding=\"utf-8\") as f:\n            rdr = csv.reader(f)\n            header = next(rdr, [])\n            data = [row for row in rdr]\n        return header, data\n    except Exception as e:\n        print(\"CSV read failed:\", e)\n        return [], []\n\n\ndef to_string(v):\n    try:\n        if v is None:\n            return \"\"\n        return str(v)\n    except Exception:\n        return \"\"\n\n\ndef normalize_value_like_old(old_value, new_value, key=None):\n    try:\n        import re\n        old_s = to_string(old_value)\n        new_s = to_string(new_value)\n        if old_s == \"\" or new_s == \"\":\n            return new_s\n\n        # Preserve leading zeros for integer-like fields\n        int_like_old = re.match(r'^[+-]?\\d+$', old_s) is not None\n        dec_like_old = re.match(r'^[+-]?\\d+\\.\\d+$', old_s) is not None\n\n        # Special-case known keys\n        lk = (key or \"\").strip().lower()\n        if lk in (\"betriebsauftrag\",):\n            # Always zero-pad to previous width if numbers\n            if re.match(r'^\\d+$', new_s) or re.match(r'^[+-]?\\d+(?:\\.0+)?$', new_s):\n                try:\n                    width = len(re.sub(r'^[+-]?', '', old_s))\n                    sign = '-' if old_s.startswith('-') else ''\n                    n = int(float(new_s))\n                    return sign + str(abs(n)).zfill(width)\n                except Exception:\n                    return new_s\n        if lk in (\"schemaversion\",):\n            # Match decimal places from old value if numeric\n            if re.match(r'^[+-]?\\d+(?:\\.\\d+)?$', new_s):\n                try:\n                    decimals = 0\n                    if dec_like_old:\n                        decimals = len(old_s.split('.')[-1])\n                    elif '.' in old_s:\n                        decimals = max(1, len(old_s.split('.')[-1]))\n                    else:\n                        decimals = 1  # ensure at least one decimal as typical schema style like 1.0\n                    val = float(new_s)\n                    fmt = \"{:.\" + str(decimals) + \"f}\"\n                    return fmt.format(val)\n                except Exception:\n                    return new_s\n\n        # Generic rules if keys unknown\n        if int_like_old:\n            # If old had leading zeros, keep width\n            try:\n                width = len(old_s.lstrip('+').lstrip('-'))\n                # detect leading zeros in old\n                had_leading_zeros = old_s.lstrip('+').lstrip('-').startswith('0') and width > 1\n                if re.match(r'^[+-]?\\d+(?:\\.0+)?$', new_s):\n                    n = int(float(new_s))\n                    s = str(abs(n))\n                    if had_leading_zeros:\n                        s = s.zfill(width)\n                    sign = '-' if old_s.startswith('-') else ''\n                    return sign + s\n            except Exception:\n                return new_s\n        if dec_like_old and re.match(r'^[+-]?\\d+(?:\\.\\d+)?$', new_s):\n            try:\n                decimals = len(old_s.split('.')[-1])\n                val = float(new_s)\n                fmt = \"{:.\" + str(decimals) + \"f}\"\n                return fmt.format(val)\n            except Exception:\n                return new_s\n\n        return new_s\n    except Exception:\n        return to_string(new_value)\n\n\ndef import_from_table(header, rows, skip_na=True, only_if_changed=True):\n    if not header:\n        print(\"No header found. Abort.\")\n        return {\"touched_leaders\": 0, \"updated_fields\": 0, \"changes\": []}\n    # Identify standard columns\n    name_to_idx = {str(h).strip(): i for i, h in enumerate(header)}\n    guid_col = None\n    for k in name_to_idx.keys():\n        if str(k).strip().lower() == \"leaderguid\":\n            guid_col = name_to_idx[k]\n            break\n    if guid_col is None:\n        print(\"Column 'LeaderGUID' not found. Cannot map rows to leaders.\")\n        return\n\n    ignore_cols = set()\n    for ign in [\"text\", \"dimstyle\"]:\n        for k, idx in name_to_idx.items():\n            if str(k).strip().lower() == ign:\n                ignore_cols.add(idx)\n\n    updated_fields = 0\n    touched_leaders = 0\n    changes = []\n\n    for row in rows:\n        if guid_col >= len(row):\n            continue\n        guid_str = to_string(row[guid_col]).strip()\n        if not guid_str:\n            continue\n        try:\n            import System\n            guid = System.Guid(guid_str)\n            rhobj = sc.doc.Objects.Find(guid)\n        except Exception:\n            rhobj = None\n        if rhobj is None:\n            continue\n        leader_id = rhobj.Id\n        changed_any = False\n        for idx, col_name in enumerate(header):\n            if idx == guid_col or idx in ignore_cols:\n                continue\n            key = str(col_name).strip()\n            if key == \"\":\n                continue\n            present = idx < len(row)\n            if not present:\n                continue\n            new_val = to_string(row[idx]).strip()\n            if skip_na and new_val.upper() == get_na_value(load_config()).upper():\n                continue\n            old_val = rs.GetUserText(leader_id, key) or \"\"\n            # normalize new value to preserve formatting like old\n            try:\n                normalized_new_val = normalize_value_like_old(old_val, new_val, key)\n            except Exception:\n                normalized_new_val = new_val\n            if only_if_changed and old_val == normalized_new_val:\n                continue\n            try:\n                rs.SetUserText(leader_id, key, normalized_new_val)\n                updated_fields += 1\n                changed_any = True\n                try:\n                    changes.append({\n                        \"LeaderGUID\": str(leader_id),\n                        \"Key\": key,\n                        \"OldValue\": old_val,\n                        \"NewValue\": normalized_new_val,\n                    })\n                except Exception:\n                    pass\n            except Exception:\n                pass\n        if changed_any:\n            # ensure LeaderGUID & SchemaVersion remain present\n            try:\n                if not rs.GetUserText(leader_id, \"LeaderGUID\"):\n                    rs.SetUserText(leader_id, \"LeaderGUID\", str(leader_id))\n                if not rs.GetUserText(leader_id, \"SchemaVersion\"):\n                    rs.SetUserText(leader_id, \"SchemaVersion\", \"1.0\")\n            except Exception:\n                pass\n            touched_leaders += 1\n\n    print(\"Leaders updated:\", touched_leaders, \"| Fields changed:\", updated_fields)\n    return {\"touched_leaders\": touched_leaders, \"updated_fields\": updated_fields, \"changes\": changes}\n\n\ndef write_diff_csv(changes, source_path):\n    try:\n        if not changes:\n            return None\n        import os\n        import csv\n        from datetime import datetime\n        directory = os.path.dirname(source_path)\n        base_name = os.path.splitext(os.path.basename(source_path))[0]\n        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n        out_path = os.path.join(directory, f\"{base_name}_diff_{timestamp}.csv\")\n        fieldnames = [\"LeaderGUID\", \"Key\", \"OldValue\", \"NewValue\"]\n        with open(out_path, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n            writer = csv.DictWriter(f, fieldnames=fieldnames)\n            writer.writeheader()\n            for rec in changes:\n                # ensure all keys exist\n                def excel_safe(val):\n                    s = \"\" if val is None else str(val)\n                    # Prevent formula injection\n                    if s.startswith('='):\n                        return \"'\" + s\n                    import re\n                    # If numeric-looking, force Excel to treat as text while displaying correctly\n                    if re.match(r'^[+-]?\\d+(?:\\.\\d+)?$', s):\n                        return '=\"' + s.replace('\"', '\"\"') + '\"'\n                    return s\n\n                row = {k: excel_safe(rec.get(k, \"\")) for k in fieldnames}\n                writer.writerow(row)\n        return out_path\n    except Exception as e:\n        try:\n            print(\"Failed to write diff CSV:\", e)\n        except Exception:\n            pass\n        return None\n\n\ndef run():\n    cfg = load_config()\n    na_value = get_na_value(cfg)\n\n    path = choose_input_file(prompt_always=True, allow_csv=False)\n    if not path or not os.path.isfile(path):\n        print(\"No file selected.\")\n        return\n\n    # Options\n    skip_na = True\n    ans = rs.GetBoolean(\"Skip NA values when importing?\", (\"SkipNA\", \"No\", \"Yes\"), True)\n    if ans is not None and len(ans) > 0:\n        skip_na = bool(ans[0])\n    only_changed = True\n    ans2 = rs.GetBoolean(\"Only update when value changed?\", (\"OnlyChanged\", \"No\", \"Yes\"), True)\n    if ans2 is not None and len(ans2) > 0:\n        only_changed = bool(ans2[0])\n\n    header = []\n    rows = []\n    if path.lower().endswith(\".xlsx\"):\n        header, rows = read_xlsx(path)\n    else:\n        header, rows = read_csv_generic(path)\n    if not header:\n        print(\"Could not read table header from:\", path)\n        return\n\n    # Import and collect changes\n    result = import_from_table(header, rows, skip_na=skip_na, only_if_changed=only_changed)\n    try:\n        changes = (result or {}).get(\"changes\", [])\n    except Exception:\n        changes = []\n    diff_path = write_diff_csv(changes, path)\n    if diff_path:\n        print(\"Diff written:\", diff_path)\n    else:\n        print(\"No changes to write or failed to write diff file.\")\n\n\nif __name__ == \"__main__\":\n    run()\n\n\n",
  "language": "python",
  "imports": [
    "Rhino",
    "rhinoscriptsyntax",
    "scriptcontext"
  ],
  "has_docstring": false
}